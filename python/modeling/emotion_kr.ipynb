{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6676e44d-85a7-444c-b547-430b5e133819",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 11:38:04.588404: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-27 11:38:04.637086: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "# 경고 메시지 무시\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83f54770-10b7-4c9f-8ed3-a3db55ed555f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 14:55:53.771039: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-24 14:55:53.781097: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-24 14:55:53.783797: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-24 14:55:53.786383: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2048] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "2023-11-24 14:55:53.789080: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-24 14:55:53.791793: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-24 14:55:53.794433: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-24 14:55:53.797056: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2048] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "2023-11-24 14:55:53.957989: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-24 14:55:53.959603: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-24 14:55:53.960882: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-24 14:55:53.962181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78942 MB memory:  -> device: 0, name: NVIDIA H100 80GB HBM3, pci bus id: 0000:00:05.0, compute capability: 9.0\n",
      "2023-11-24 14:55:55.701479: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.bias', 'bert.embeddings.position_ids', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('klue/bert-base')\n",
    "kobert_model = TFBertModel.from_pretrained('klue/bert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64fbe73e-8d9c-4611-b090-1c9c946315f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in ./miniforge3/envs/tf212_py310/lib/python3.10/site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in ./miniforge3/envs/tf212_py310/lib/python3.10/site-packages (from openpyxl) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6282b8f-af3f-44ff-9319-6d7397a9f45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "data = pd.read_excel(\"./감성대화말뭉치(최종데이터)_Training.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db13845c-04a8-46bc-a1c4-1233d8d1d294",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>연령</th>\n",
       "      <th>성별</th>\n",
       "      <th>상황키워드</th>\n",
       "      <th>신체질환</th>\n",
       "      <th>감정_대분류</th>\n",
       "      <th>감정_소분류</th>\n",
       "      <th>사람문장1</th>\n",
       "      <th>시스템문장1</th>\n",
       "      <th>사람문장2</th>\n",
       "      <th>시스템문장2</th>\n",
       "      <th>사람문장3</th>\n",
       "      <th>시스템문장3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>청년</td>\n",
       "      <td>여성</td>\n",
       "      <td>진로,취업,직장</td>\n",
       "      <td>해당없음</td>\n",
       "      <td>분노</td>\n",
       "      <td>노여워하는</td>\n",
       "      <td>일은 왜 해도 해도 끝이 없을까? 화가 난다.</td>\n",
       "      <td>많이 힘드시겠어요. 주위에 의논할 상대가 있나요?</td>\n",
       "      <td>그냥 내가 해결하는 게 나아. 남들한테 부담 주고 싶지도 않고.</td>\n",
       "      <td>혼자 해결하기로 했군요. 혼자서 해결하기 힘들면 주위에 의논할 사람을 찾아보세요.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>청년</td>\n",
       "      <td>여성</td>\n",
       "      <td>진로,취업,직장</td>\n",
       "      <td>해당없음</td>\n",
       "      <td>분노</td>\n",
       "      <td>노여워하는</td>\n",
       "      <td>이번 달에 또 급여가 깎였어! 물가는 오르는데 월급만 자꾸 깎이니까 너무 화가 나.</td>\n",
       "      <td>급여가 줄어 속상하시겠어요. 월급이 줄어든 것을 어떻게 보완하실 건가요?</td>\n",
       "      <td>최대한 지출을 억제해야겠어. 월급이 줄어들었으니 고정지출을 줄일 수밖에 없을 것 같아.</td>\n",
       "      <td>월급이 줄어든 만큼 소비를 줄일 계획이군요.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>청년</td>\n",
       "      <td>여성</td>\n",
       "      <td>진로,취업,직장</td>\n",
       "      <td>해당없음</td>\n",
       "      <td>분노</td>\n",
       "      <td>노여워하는</td>\n",
       "      <td>회사에 신입이 들어왔는데 말투가 거슬려. 그런 애를 매일 봐야 한다고 생각하니까 스...</td>\n",
       "      <td>회사 동료 때문에 스트레스를 많이 받는 것 같아요. 문제 해결을 위해 어떤 노력을 ...</td>\n",
       "      <td>잘 안 맞는 사람이랑 억지로 잘 지내는 것보단 조금은 거리를 두고 예의를 갖춰서 대...</td>\n",
       "      <td>스트레스받지 않기 위해선 인간관계에 있어 약간의 거리를 두는 게 좋겠군요.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>청년</td>\n",
       "      <td>여성</td>\n",
       "      <td>진로,취업,직장</td>\n",
       "      <td>해당없음</td>\n",
       "      <td>분노</td>\n",
       "      <td>노여워하는</td>\n",
       "      <td>직장에서 막내라는 이유로 나에게만 온갖 심부름을 시켜. 일도 많은 데 정말 분하고 ...</td>\n",
       "      <td>관련 없는 심부름을 모두 하게 되어서 노여우시군요. 어떤 것이 상황을 나아질 수 있...</td>\n",
       "      <td>직장 사람들과 솔직하게 이야기해보고 싶어. 일하는 데에 방해된다고.</td>\n",
       "      <td>직장 사람들과 이야기를 해 보겠다고 결심하셨군요.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>청년</td>\n",
       "      <td>여성</td>\n",
       "      <td>진로,취업,직장</td>\n",
       "      <td>해당없음</td>\n",
       "      <td>분노</td>\n",
       "      <td>노여워하는</td>\n",
       "      <td>얼마 전 입사한 신입사원이 나를 무시하는 것 같아서 너무 화가 나.</td>\n",
       "      <td>무시하는 것 같은 태도에 화가 나셨군요. 상대방의 어떤 행동이 그런 감정을 유발하는...</td>\n",
       "      <td>상사인 나에게 먼저 인사하지 않아서 매일 내가 먼저 인사한다고!</td>\n",
       "      <td>항상 먼저 인사하게 되어 화가 나셨군요. 어떻게 하면 신입사원에게 화났음을 표현할 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51625</th>\n",
       "      <td>51626</td>\n",
       "      <td>노년</td>\n",
       "      <td>남성</td>\n",
       "      <td>재정</td>\n",
       "      <td>만성질환 무</td>\n",
       "      <td>분노</td>\n",
       "      <td>성가신</td>\n",
       "      <td>나이가 먹고 이제 돈도 못 벌어 오니까 어떻게 살아가야 할지 막막해. 능력도 없고.</td>\n",
       "      <td>경제적인 문제 때문에 막막하시군요. 마음이 편치 않으시겠어요.</td>\n",
       "      <td>아무것도 할 수 없는 내가 무가치하게 느껴지고 실망스러워.</td>\n",
       "      <td>지금 할 수 있는 가장 합리적인 행동은 무엇인가요?</td>\n",
       "      <td>노년층을 위한 경제적 지원이나 부업 같은 것도 알아보아야겠어.</td>\n",
       "      <td>좋은 결과 얻으시길 바랄게요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51626</th>\n",
       "      <td>51627</td>\n",
       "      <td>노년</td>\n",
       "      <td>여성</td>\n",
       "      <td>재정</td>\n",
       "      <td>만성질환 무</td>\n",
       "      <td>불안</td>\n",
       "      <td>초조한</td>\n",
       "      <td>몸이 많이 약해졌나 봐. 이제 전과 같이 일하지 못할 것 같아 너무 짜증 나.</td>\n",
       "      <td>건강에 대한 어려움 때문에 기분이 좋지 않으시군요. 속상하시겠어요.</td>\n",
       "      <td>마음 같아서는 다 할 수 있는 일인데 이젠 몸이 안 따라와 주니 화만 나.</td>\n",
       "      <td>어떻게 하면 지금의 기분을 나아지게 할 수 있을까요?</td>\n",
       "      <td>남편과 함께 게이트볼이나 치러 가야겠어. 그럼 기분이 나아질 것 같아.</td>\n",
       "      <td>남편과 함께하는 좋은 외출 시간 되시길 바랄게요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51627</th>\n",
       "      <td>51628</td>\n",
       "      <td>노년</td>\n",
       "      <td>여성</td>\n",
       "      <td>재정</td>\n",
       "      <td>만성질환 무</td>\n",
       "      <td>상처</td>\n",
       "      <td>희생된</td>\n",
       "      <td>이제 어떻게 해야 할지 모르겠어. 남편도 그렇고 노후 준비도 안 되어서 미래가 걱정돼.</td>\n",
       "      <td>노후 준비에 대한 어려움 때문에 걱정이 많으시겠어요.</td>\n",
       "      <td>주변 사람들은 다 노후 준비도 잘해두었던데 난 어떻게 해야 할지 모르겠어. 막막하기...</td>\n",
       "      <td>지금의 상황에서 할 수 있는 가장 좋은 행동이 무엇일까요?</td>\n",
       "      <td>남편과 함께 실버 일자리나 노년층을 위한 국가 지원에 대해 자세히 알아보아야겠어.</td>\n",
       "      <td>좋은 정보 많이 얻으셔서 걱정을 좀 덜으셨으면 좋겠어요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51628</th>\n",
       "      <td>51629</td>\n",
       "      <td>노년</td>\n",
       "      <td>여성</td>\n",
       "      <td>대인관계</td>\n",
       "      <td>만성질환 무</td>\n",
       "      <td>불안</td>\n",
       "      <td>걱정스러운</td>\n",
       "      <td>몇십 년을 함께 살았던 남편과 이혼했어. 그동안의 세월에 배신감을 느끼고 너무 화가 나.</td>\n",
       "      <td>가족과의 문제 때문에 속상하시겠어요.</td>\n",
       "      <td>이제 할 수 있는 일도 없고 이렇게 힘들게 사는 게 불만스럽기만 해.</td>\n",
       "      <td>지금의 감정을 나아지게 할 수 있는 어떤 방법이 있을까요?</td>\n",
       "      <td>함께 친하게 지내던 동네 언니 동생들과 빈자리를 조금이나마 채울까 해.</td>\n",
       "      <td>지인분들과 좋은 시간 보내셨으면 좋겠어요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51629</th>\n",
       "      <td>51630</td>\n",
       "      <td>노년</td>\n",
       "      <td>여성</td>\n",
       "      <td>대인관계</td>\n",
       "      <td>만성질환 무</td>\n",
       "      <td>상처</td>\n",
       "      <td>배신당한</td>\n",
       "      <td>남편과 결혼한 지 사십 년이야. 이제 사람 만나는 것도 버겁고 알던 사람도 점점 사라져.</td>\n",
       "      <td>대인관계에 대한 어려움 때문에 걱정되시고 속상하시겠어요.</td>\n",
       "      <td>사람들을 만나는 것이 어려워. 자꾸 사람들을 의심하게만 되고 말이야.</td>\n",
       "      <td>어떻게 하면 지금의 상황에 변화를 만들어낼 수 있을까요?</td>\n",
       "      <td>사람들을 볼 때 의심하고 불신하는 마음을 억눌러야겠어. 사람들을 색안경을 끼고 보지...</td>\n",
       "      <td>원하시는 대로 가지고 계시던 걱정이 잘 해결되셨으면 좋겠어요.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51630 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  연령  성별     상황키워드    신체질환 감정_대분류 감정_소분류  \\\n",
       "0               1  청년  여성  진로,취업,직장    해당없음     분노  노여워하는   \n",
       "1               2  청년  여성  진로,취업,직장    해당없음     분노  노여워하는   \n",
       "2               3  청년  여성  진로,취업,직장    해당없음     분노  노여워하는   \n",
       "3               4  청년  여성  진로,취업,직장    해당없음     분노  노여워하는   \n",
       "4               5  청년  여성  진로,취업,직장    해당없음     분노  노여워하는   \n",
       "...           ...  ..  ..       ...     ...    ...    ...   \n",
       "51625       51626  노년  남성        재정  만성질환 무     분노    성가신   \n",
       "51626       51627  노년  여성        재정  만성질환 무     불안    초조한   \n",
       "51627       51628  노년  여성        재정  만성질환 무     상처    희생된   \n",
       "51628       51629  노년  여성      대인관계  만성질환 무     불안  걱정스러운   \n",
       "51629       51630  노년  여성      대인관계  만성질환 무     상처   배신당한   \n",
       "\n",
       "                                                   사람문장1  \\\n",
       "0                              일은 왜 해도 해도 끝이 없을까? 화가 난다.   \n",
       "1         이번 달에 또 급여가 깎였어! 물가는 오르는데 월급만 자꾸 깎이니까 너무 화가 나.   \n",
       "2      회사에 신입이 들어왔는데 말투가 거슬려. 그런 애를 매일 봐야 한다고 생각하니까 스...   \n",
       "3      직장에서 막내라는 이유로 나에게만 온갖 심부름을 시켜. 일도 많은 데 정말 분하고 ...   \n",
       "4                  얼마 전 입사한 신입사원이 나를 무시하는 것 같아서 너무 화가 나.   \n",
       "...                                                  ...   \n",
       "51625     나이가 먹고 이제 돈도 못 벌어 오니까 어떻게 살아가야 할지 막막해. 능력도 없고.   \n",
       "51626        몸이 많이 약해졌나 봐. 이제 전과 같이 일하지 못할 것 같아 너무 짜증 나.   \n",
       "51627   이제 어떻게 해야 할지 모르겠어. 남편도 그렇고 노후 준비도 안 되어서 미래가 걱정돼.   \n",
       "51628  몇십 년을 함께 살았던 남편과 이혼했어. 그동안의 세월에 배신감을 느끼고 너무 화가 나.   \n",
       "51629  남편과 결혼한 지 사십 년이야. 이제 사람 만나는 것도 버겁고 알던 사람도 점점 사라져.   \n",
       "\n",
       "                                                  시스템문장1  \\\n",
       "0                            많이 힘드시겠어요. 주위에 의논할 상대가 있나요?   \n",
       "1               급여가 줄어 속상하시겠어요. 월급이 줄어든 것을 어떻게 보완하실 건가요?   \n",
       "2      회사 동료 때문에 스트레스를 많이 받는 것 같아요. 문제 해결을 위해 어떤 노력을 ...   \n",
       "3      관련 없는 심부름을 모두 하게 되어서 노여우시군요. 어떤 것이 상황을 나아질 수 있...   \n",
       "4      무시하는 것 같은 태도에 화가 나셨군요. 상대방의 어떤 행동이 그런 감정을 유발하는...   \n",
       "...                                                  ...   \n",
       "51625                 경제적인 문제 때문에 막막하시군요. 마음이 편치 않으시겠어요.   \n",
       "51626              건강에 대한 어려움 때문에 기분이 좋지 않으시군요. 속상하시겠어요.   \n",
       "51627                      노후 준비에 대한 어려움 때문에 걱정이 많으시겠어요.   \n",
       "51628                               가족과의 문제 때문에 속상하시겠어요.   \n",
       "51629                    대인관계에 대한 어려움 때문에 걱정되시고 속상하시겠어요.   \n",
       "\n",
       "                                                   사람문장2  \\\n",
       "0                    그냥 내가 해결하는 게 나아. 남들한테 부담 주고 싶지도 않고.   \n",
       "1       최대한 지출을 억제해야겠어. 월급이 줄어들었으니 고정지출을 줄일 수밖에 없을 것 같아.   \n",
       "2      잘 안 맞는 사람이랑 억지로 잘 지내는 것보단 조금은 거리를 두고 예의를 갖춰서 대...   \n",
       "3                  직장 사람들과 솔직하게 이야기해보고 싶어. 일하는 데에 방해된다고.   \n",
       "4                    상사인 나에게 먼저 인사하지 않아서 매일 내가 먼저 인사한다고!   \n",
       "...                                                  ...   \n",
       "51625                   아무것도 할 수 없는 내가 무가치하게 느껴지고 실망스러워.   \n",
       "51626          마음 같아서는 다 할 수 있는 일인데 이젠 몸이 안 따라와 주니 화만 나.   \n",
       "51627  주변 사람들은 다 노후 준비도 잘해두었던데 난 어떻게 해야 할지 모르겠어. 막막하기...   \n",
       "51628             이제 할 수 있는 일도 없고 이렇게 힘들게 사는 게 불만스럽기만 해.   \n",
       "51629             사람들을 만나는 것이 어려워. 자꾸 사람들을 의심하게만 되고 말이야.   \n",
       "\n",
       "                                                  시스템문장2  \\\n",
       "0         혼자 해결하기로 했군요. 혼자서 해결하기 힘들면 주위에 의논할 사람을 찾아보세요.    \n",
       "1                               월급이 줄어든 만큼 소비를 줄일 계획이군요.   \n",
       "2              스트레스받지 않기 위해선 인간관계에 있어 약간의 거리를 두는 게 좋겠군요.   \n",
       "3                            직장 사람들과 이야기를 해 보겠다고 결심하셨군요.   \n",
       "4      항상 먼저 인사하게 되어 화가 나셨군요. 어떻게 하면 신입사원에게 화났음을 표현할 ...   \n",
       "...                                                  ...   \n",
       "51625                       지금 할 수 있는 가장 합리적인 행동은 무엇인가요?   \n",
       "51626                      어떻게 하면 지금의 기분을 나아지게 할 수 있을까요?   \n",
       "51627                   지금의 상황에서 할 수 있는 가장 좋은 행동이 무엇일까요?   \n",
       "51628                   지금의 감정을 나아지게 할 수 있는 어떤 방법이 있을까요?   \n",
       "51629                    어떻게 하면 지금의 상황에 변화를 만들어낼 수 있을까요?   \n",
       "\n",
       "                                                   사람문장3  \\\n",
       "0                                                    NaN   \n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "51625                 노년층을 위한 경제적 지원이나 부업 같은 것도 알아보아야겠어.   \n",
       "51626            남편과 함께 게이트볼이나 치러 가야겠어. 그럼 기분이 나아질 것 같아.   \n",
       "51627      남편과 함께 실버 일자리나 노년층을 위한 국가 지원에 대해 자세히 알아보아야겠어.   \n",
       "51628            함께 친하게 지내던 동네 언니 동생들과 빈자리를 조금이나마 채울까 해.   \n",
       "51629  사람들을 볼 때 의심하고 불신하는 마음을 억눌러야겠어. 사람들을 색안경을 끼고 보지...   \n",
       "\n",
       "                                   시스템문장3  \n",
       "0                                     NaN  \n",
       "1                                     NaN  \n",
       "2                                     NaN  \n",
       "3                                     NaN  \n",
       "4                                     NaN  \n",
       "...                                   ...  \n",
       "51625                    좋은 결과 얻으시길 바랄게요.  \n",
       "51626         남편과 함께하는 좋은 외출 시간 되시길 바랄게요.  \n",
       "51627     좋은 정보 많이 얻으셔서 걱정을 좀 덜으셨으면 좋겠어요.  \n",
       "51628             지인분들과 좋은 시간 보내셨으면 좋겠어요.  \n",
       "51629  원하시는 대로 가지고 계시던 걱정이 잘 해결되셨으면 좋겠어요.  \n",
       "\n",
       "[51630 rows x 13 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbfe6294-59d9-4db2-b0ba-7f4e8cd66595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가사 단어 100토큰으로줄이기\n",
    "for i in range (len(data[\"사람문장1\"])):\n",
    "    list1=list(data[\"사람문장1\"][i].split(\" \"))\n",
    "    list1= list1[:100]\n",
    "    data[\"사람문장1\"][i]=\" \".join(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10dbef7d-1083-4856-af6c-df92f7ad0c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[[\"감정_대분류\",\"사람문장1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d644808-c6c9-4c0d-a12c-6d5a6030dbda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>감정_대분류</th>\n",
       "      <th>사람문장1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>분노</td>\n",
       "      <td>일은 왜 해도 해도 끝이 없을까? 화가 난다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>분노</td>\n",
       "      <td>이번 달에 또 급여가 깎였어! 물가는 오르는데 월급만 자꾸 깎이니까 너무 화가 나.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>분노</td>\n",
       "      <td>회사에 신입이 들어왔는데 말투가 거슬려. 그런 애를 매일 봐야 한다고 생각하니까 스...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>분노</td>\n",
       "      <td>직장에서 막내라는 이유로 나에게만 온갖 심부름을 시켜. 일도 많은 데 정말 분하고 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>분노</td>\n",
       "      <td>얼마 전 입사한 신입사원이 나를 무시하는 것 같아서 너무 화가 나.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51625</th>\n",
       "      <td>분노</td>\n",
       "      <td>나이가 먹고 이제 돈도 못 벌어 오니까 어떻게 살아가야 할지 막막해. 능력도 없고.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51626</th>\n",
       "      <td>불안</td>\n",
       "      <td>몸이 많이 약해졌나 봐. 이제 전과 같이 일하지 못할 것 같아 너무 짜증 나.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51627</th>\n",
       "      <td>상처</td>\n",
       "      <td>이제 어떻게 해야 할지 모르겠어. 남편도 그렇고 노후 준비도 안 되어서 미래가 걱정돼.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51628</th>\n",
       "      <td>불안</td>\n",
       "      <td>몇십 년을 함께 살았던 남편과 이혼했어. 그동안의 세월에 배신감을 느끼고 너무 화가 나.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51629</th>\n",
       "      <td>상처</td>\n",
       "      <td>남편과 결혼한 지 사십 년이야. 이제 사람 만나는 것도 버겁고 알던 사람도 점점 사라져.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51630 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      감정_대분류                                              사람문장1\n",
       "0         분노                          일은 왜 해도 해도 끝이 없을까? 화가 난다.\n",
       "1         분노     이번 달에 또 급여가 깎였어! 물가는 오르는데 월급만 자꾸 깎이니까 너무 화가 나.\n",
       "2         분노  회사에 신입이 들어왔는데 말투가 거슬려. 그런 애를 매일 봐야 한다고 생각하니까 스...\n",
       "3         분노  직장에서 막내라는 이유로 나에게만 온갖 심부름을 시켜. 일도 많은 데 정말 분하고 ...\n",
       "4         분노              얼마 전 입사한 신입사원이 나를 무시하는 것 같아서 너무 화가 나.\n",
       "...      ...                                                ...\n",
       "51625     분노     나이가 먹고 이제 돈도 못 벌어 오니까 어떻게 살아가야 할지 막막해. 능력도 없고.\n",
       "51626     불안        몸이 많이 약해졌나 봐. 이제 전과 같이 일하지 못할 것 같아 너무 짜증 나.\n",
       "51627     상처   이제 어떻게 해야 할지 모르겠어. 남편도 그렇고 노후 준비도 안 되어서 미래가 걱정돼.\n",
       "51628     불안  몇십 년을 함께 살았던 남편과 이혼했어. 그동안의 세월에 배신감을 느끼고 너무 화가 나.\n",
       "51629     상처  남편과 결혼한 지 사십 년이야. 이제 사람 만나는 것도 버겁고 알던 사람도 점점 사라져.\n",
       "\n",
       "[51630 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee63a1f1-44be-4dd9-9137-2571b7ca269d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['분노', '기쁨', '불안', '당황', '슬픔', '상처'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['감정_대분류'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "481dfdae-4815-4748-bbec-03bb096f50fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감정 태그를 숫자로 매핑\n",
    "tag_mapping = {tag: idx for idx, tag in enumerate(data['감정_대분류'].unique())}\n",
    "inverse_tag_mapping = {v: k for k, v in tag_mapping.items()}\n",
    "data['감정_대분류_encoded'] = data['감정_대분류'].map(tag_mapping)\n",
    "\n",
    "# 데이터 분할\n",
    "train,test= train_test_split(data[[\"사람문장1\",'감정_대분류_encoded']], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06b23d1f-e6e7-4bb9-9fda-73c470deb954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>사람문장1</th>\n",
       "      <th>감정_대분류_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21798</th>\n",
       "      <td>오늘 학교 화장실에서 친구들이 나를 가두고 변기 물을 뿌려서 구역질났어.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38273</th>\n",
       "      <td>요즘 자꾸 깜박깜박 뭘 자주 잊어버려.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48537</th>\n",
       "      <td>갱년기에 접어들면서 나 자신이 하찮게 느껴지고 불안감에 다른 사람들을 믿지 못하게 됐어.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7815</th>\n",
       "      <td>회사 어떤 여직원이 자기보다 나이가 많은 줄 알았다며 나에게 이야기를 하는 거 있지...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42449</th>\n",
       "      <td>시험공부 하느라 친구들의 연락을 다 거절해서 미안하고 친구들이 날 싫어할까 봐 두려워.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>나는 친구가 너무 없어.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44732</th>\n",
       "      <td>불편한 다리 때문에 더는 일을 못 하니까 아무도 날 찾지 않아. 삶이 허탈하게 느껴져.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38158</th>\n",
       "      <td>전에는 일본에서 황혼이혼이라는 말이 유행하더니 이제는 우리나라도 마찬가지인가봐. 그...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>나랑 대화하는 걸 좋아하는 할머니가 있는데 그분 덕분에 나도 기분이 좋아.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>문제가 많은 프로젝트에 최종 결정을 내려야 하는데 어떤 게 맞는지 모르겠어.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41304 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   사람문장1  감정_대분류_encoded\n",
       "21798           오늘 학교 화장실에서 친구들이 나를 가두고 변기 물을 뿌려서 구역질났어.               0\n",
       "38273                              요즘 자꾸 깜박깜박 뭘 자주 잊어버려.               4\n",
       "48537  갱년기에 접어들면서 나 자신이 하찮게 느껴지고 불안감에 다른 사람들을 믿지 못하게 됐어.               5\n",
       "7815   회사 어떤 여직원이 자기보다 나이가 많은 줄 알았다며 나에게 이야기를 하는 거 있지...               5\n",
       "42449   시험공부 하느라 친구들의 연락을 다 거절해서 미안하고 친구들이 날 싫어할까 봐 두려워.               3\n",
       "...                                                  ...             ...\n",
       "11284                                      나는 친구가 너무 없어.               2\n",
       "44732   불편한 다리 때문에 더는 일을 못 하니까 아무도 날 찾지 않아. 삶이 허탈하게 느껴져.               5\n",
       "38158  전에는 일본에서 황혼이혼이라는 말이 유행하더니 이제는 우리나라도 마찬가지인가봐. 그...               2\n",
       "860            나랑 대화하는 걸 좋아하는 할머니가 있는데 그분 덕분에 나도 기분이 좋아.               1\n",
       "15795         문제가 많은 프로젝트에 최종 결정을 내려야 하는데 어떤 게 맞는지 모르겠어.               3\n",
       "\n",
       "[41304 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd9828d6-69c0-46b1-b8eb-f6069d1d1590",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x_train \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m(\n\u001b[1;32m      2\u001b[0m     text\u001b[38;5;241m=\u001b[39mtrain\u001b[38;5;241m.\u001b[39m사람문장1\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[1;32m      3\u001b[0m     add_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      4\u001b[0m     max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[1;32m      5\u001b[0m     truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      6\u001b[0m     padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      7\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m     return_token_type_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      9\u001b[0m     return_attention_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m     verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     13\u001b[0m x_test \u001b[38;5;241m=\u001b[39m tokenizer(\n\u001b[1;32m     14\u001b[0m     text\u001b[38;5;241m=\u001b[39mtest\u001b[38;5;241m.\u001b[39m사람문장1\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[1;32m     15\u001b[0m     add_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     return_attention_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     22\u001b[0m     verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "x_train = tokenizer(\n",
    "    text=train.사람문장1.tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=50,\n",
    "    truncation=True,\n",
    "    padding='max_length', \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)\n",
    "\n",
    "\n",
    "x_test = tokenizer(\n",
    "    text=test.사람문장1.tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=50,\n",
    "    truncation=True,\n",
    "    padding='max_length', \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f0ce4a0-23b1-4a94-8997-04da2a16ac4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "830ce0be-0b12-4cde-8ddb-a2a4590c8abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 50\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "input_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
    "input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n",
    "embeddings = kobert_model(input_ids,attention_mask = input_mask)[0] #(0 is the last hidden states,1 means pooler_output)\n",
    "out = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
    "out = Dense(256, activation='relu')(out)\n",
    "out = tf.keras.layers.Dropout(0.4)(out)\n",
    "out = Dense(32,activation = 'relu')(out)\n",
    "\n",
    "y = Dense(6,activation = 'softmax')(out)\n",
    "    \n",
    "model = tf.keras.Model(inputs=[input_ids, input_mask], outputs=y)\n",
    "model.layers[2].trainable = True\n",
    "# for training bert our lr must be so small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b571216-ba77-4e58-aa7b-fde2e90aee22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 50)]         0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, 50)]         0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  110617344   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 50,                                                \n",
      "                                768),                                                             \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " global_max_pooling1d (GlobalMa  (None, 768)         0           ['tf_bert_model[0][0]']          \n",
      " xPooling1D)                                                                                      \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          196864      ['global_max_pooling1d[0][0]']   \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 256)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 32)           8224        ['dropout_37[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 6)            198         ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 110,822,630\n",
      "Trainable params: 110,822,630\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7084fadb-a839-4646-9ead-1a5b0e7a1195",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.legacy.Adam(\n",
    "    learning_rate=5e-05, # this learning rate is for bert model , taken from huggingface website \n",
    "    \n",
    "    clipnorm=1.0)\n",
    "\n",
    "# Set loss and metrics\n",
    "loss =CategoricalCrossentropy(from_logits = True)\n",
    "metric = CategoricalAccuracy('balanced_accuracy'),\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = loss, \n",
    "    metrics = metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02464d1f-2c89-4ecc-95ad-892b9eab674d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "646/646 [==============================] - 56s 65ms/step - loss: 1.3196 - balanced_accuracy: 0.4906 - val_loss: 1.1842 - val_balanced_accuracy: 0.5644\n",
      "Epoch 2/50\n",
      "646/646 [==============================] - 41s 63ms/step - loss: 1.1146 - balanced_accuracy: 0.5859 - val_loss: 1.1530 - val_balanced_accuracy: 0.5714\n",
      "Epoch 3/50\n",
      "646/646 [==============================] - 40s 63ms/step - loss: 1.0117 - balanced_accuracy: 0.6273 - val_loss: 1.1407 - val_balanced_accuracy: 0.5788\n",
      "Epoch 4/50\n",
      "  7/646 [..............................] - ETA: 36s - loss: 0.8836 - balanced_accuracy: 0.7009"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mto_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m감정_대분류_encoded\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m감정_대분류_encoded\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf212_py310/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf212_py310/lib/python3.10/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniforge3/envs/tf212_py310/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf212_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf212_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniforge3/envs/tf212_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf212_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniforge3/envs/tf212_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf212_py310/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_history = model.fit(\n",
    "    x ={'input_ids':x_train['input_ids'],'attention_mask':x_train['attention_mask']} ,\n",
    "    y = to_categorical(train.감정_대분류_encoded),\n",
    "    validation_data = (\n",
    "    {'input_ids':x_test['input_ids'],'attention_mask':x_test['attention_mask']}, to_categorical(test.감정_대분류_encoded)),\n",
    "    epochs=50,\n",
    "    batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa1c0006-1454-4cd5-a9fb-3a456e8255ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 8s 17ms/step\n"
     ]
    }
   ],
   "source": [
    "# 예측 결과를 원래 태그로 변환\n",
    "predictions = model.predict(\n",
    "   {'input_ids':x_test['input_ids'],'attention_mask':x_test['attention_mask']})\n",
    "predicted_tags = np.argmax(predictions, axis=1)\n",
    "# predicted_tags = [inverse_tag_mapping[tag] for tag in predicted_tags]\n",
    "\n",
    "# print(\"Predicted Tags:\", predicted_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15f6d65d-3f25-4fc7-92f1-1bee8acf0db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"predict\"]=predicted_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4cf4bb0-bc92-456a-bed2-f4d8f5bc1418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>사람문장1</th>\n",
       "      <th>감정_대분류_encoded</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44927</th>\n",
       "      <td>요즘 주변에서 부모님들과 여행 다녀온 아이들을 보면 너무 부러워.</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25924</th>\n",
       "      <td>나와 남편은 귀가 얇아서 사기를 잘 당해서 재정이 취약하고 늘 불안해.</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47384</th>\n",
       "      <td>오늘도 폐지 주워 오천 원밖에 못 벌었어. 앞으로 어떻게 살지 왜 난 이따위 사람일까.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8570</th>\n",
       "      <td>우리 언니는 왜 나한테 사사건건 간섭일까? 스트레스다 정말.</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3227</th>\n",
       "      <td>오늘 이직 면접을 보고 왔는데 괜히 보고 왔나 봐. 면접 간 게 후회돼.</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19002</th>\n",
       "      <td>옆집 할아버지가 입원을 했는데 마침 우리 집 농기계가 고장이 났어. 말도 없이 빌려...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13152</th>\n",
       "      <td>내 친구들을 볼 때마다 자존감이 낮아져.</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28051</th>\n",
       "      <td>잘못된 종류의 빵을 사 가서 폭력을 당하는 모습을 좋아하던 아이한테 들켰어.</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47896</th>\n",
       "      <td>노후 준비를 아직 하지 못한 내가 싫어.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31983</th>\n",
       "      <td>친구한테 사기를 당했어.</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10326 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   사람문장1  감정_대분류_encoded  \\\n",
       "44927               요즘 주변에서 부모님들과 여행 다녀온 아이들을 보면 너무 부러워.               3   \n",
       "25924            나와 남편은 귀가 얇아서 사기를 잘 당해서 재정이 취약하고 늘 불안해.               2   \n",
       "47384   오늘도 폐지 주워 오천 원밖에 못 벌었어. 앞으로 어떻게 살지 왜 난 이따위 사람일까.               0   \n",
       "8570                   우리 언니는 왜 나한테 사사건건 간섭일까? 스트레스다 정말.               2   \n",
       "3227            오늘 이직 면접을 보고 왔는데 괜히 보고 왔나 봐. 면접 간 게 후회돼.               2   \n",
       "...                                                  ...             ...   \n",
       "19002  옆집 할아버지가 입원을 했는데 마침 우리 집 농기계가 고장이 났어. 말도 없이 빌려...               3   \n",
       "13152                             내 친구들을 볼 때마다 자존감이 낮아져.               2   \n",
       "28051         잘못된 종류의 빵을 사 가서 폭력을 당하는 모습을 좋아하던 아이한테 들켰어.               3   \n",
       "47896                             노후 준비를 아직 하지 못한 내가 싫어.               0   \n",
       "31983                                      친구한테 사기를 당했어.               4   \n",
       "\n",
       "       predict  \n",
       "44927        3  \n",
       "25924        2  \n",
       "47384        0  \n",
       "8570         2  \n",
       "3227         4  \n",
       "...        ...  \n",
       "19002        3  \n",
       "13152        0  \n",
       "28051        3  \n",
       "47896        0  \n",
       "31983        5  \n",
       "\n",
       "[10326 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d0a8b57-f199-4ea7-bd98-884274ecb6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.55      0.53      1831\n",
      "           1       0.91      0.83      0.87      1206\n",
      "           2       0.57      0.54      0.55      1891\n",
      "           3       0.57      0.43      0.49      1718\n",
      "           4       0.52      0.55      0.54      1843\n",
      "           5       0.43      0.53      0.48      1837\n",
      "\n",
      "    accuracy                           0.56     10326\n",
      "   macro avg       0.59      0.57      0.58     10326\n",
      "weighted avg       0.57      0.56      0.56     10326\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 예측 결과와 실제 레이블을 가지고 classification report 생성\n",
    "y_true = test.감정_대분류_encoded\n",
    "y_pred =np.argmax(predictions, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a10f77d4-7cb0-421c-a596-f56b1e6ab95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "감정_대분류_encoded\n",
       "2    9320\n",
       "0    9160\n",
       "5    9143\n",
       "4    9125\n",
       "3    8756\n",
       "1    6126\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"감정_대분류_encoded\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a342661c-3c04-4e7c-b71b-c315ef919c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "감정_대분류\n",
       "불안    9320\n",
       "분노    9160\n",
       "상처    9143\n",
       "슬픔    9125\n",
       "당황    8756\n",
       "기쁨    6126\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"감정_대분류\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b573764-28ac-485f-a1a5-5f8d805e3498",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data=pd.read_excel(\"./감성대화말뭉치(최종데이터)_Validation.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3457e567-fee2-4bec-bcc5-6d40ef48c766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감정 태그를 숫자로 매핑\n",
    "tag_mapping = {tag: idx for idx, tag in enumerate(val_data['감정_대분류'].unique())}\n",
    "inverse_tag_mapping = {v: k for k, v in tag_mapping.items()}\n",
    "val_data['감정_대분류_encoded'] = val_data['감정_대분류'].map(tag_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e96183b3-a241-40cf-99a7-2be7344c7f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_train = tokenizer(\n",
    "    text=val_data.사람문장1.tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=50,\n",
    "    truncation=True,\n",
    "    padding='max_length', \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f1be1ca-40fe-4071-bf64-722011f14e80",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/208 [==============================] - 4s 18ms/step\n",
      "Predicted Tags: ['당황', '기쁨', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '분노', '분노', '분노', '기쁨', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '상처', '불안', '기쁨', '상처', '기쁨', '기쁨', '기쁨', '기쁨', '상처', '기쁨', '기쁨', '분노', '슬픔', '당황', '슬픔', '슬픔', '슬픔', '슬픔', '기쁨', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '기쁨', '기쁨', '기쁨', '기쁨', '상처', '불안', '기쁨', '기쁨', '당황', '상처', '기쁨', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '분노', '불안', '불안', '불안', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '불안', '불안', '불안', '당황', '불안', '상처', '불안', '불안', '불안', '불안', '당황', '불안', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '당황', '상처', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '상처', '상처', '분노', '분노', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '상처', '불안', '불안', '불안', '불안', '분노', '불안', '불안', '불안', '불안', '불안', '상처', '불안', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '불안', '불안', '불안', '상처', '상처', '불안', '불안', '불안', '상처', '기쁨', '기쁨', '상처', '기쁨', '기쁨', '기쁨', '기쁨', '불안', '기쁨', '상처', '기쁨', '기쁨', '분노', '상처', '분노', '불안', '당황', '상처', '분노', '당황', '분노', '상처', '분노', '분노', '상처', '상처', '기쁨', '당황', '분노', '상처', '기쁨', '상처', '상처', '기쁨', '상처', '상처', '상처', '분노', '분노', '불안', '불안', '분노', '상처', '기쁨', '분노', '당황', '분노', '당황', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '상처', '상처', '분노', '분노', '분노', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '불안', '슬픔', '불안', '기쁨', '불안', '불안', '불안', '불안', '불안', '분노', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '상처', '불안', '불안', '상처', '불안', '당황', '당황', '불안', '불안', '불안', '당황', '불안', '불안', '불안', '불안', '불안', '분노', '불안', '불안', '분노', '불안', '불안', '기쁨', '기쁨', '기쁨', '분노', '기쁨', '기쁨', '기쁨', '불안', '불안', '기쁨', '기쁨', '분노', '분노', '분노', '분노', '분노', '분노', '상처', '분노', '분노', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '상처', '불안', '불안', '분노', '불안', '불안', '불안', '불안', '불안', '불안', '분노', '불안', '당황', '분노', '불안', '불안', '불안', '불안', '불안', '불안', '기쁨', '불안', '상처', '불안', '불안', '불안', '불안', '불안', '분노', '불안', '불안', '불안', '불안', '불안', '상처', '상처', '불안', '불안', '슬픔', '상처', '불안', '불안', '불안', '분노', '불안', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '분노', '상처', '분노', '상처', '상처', '기쁨', '불안', '분노', '기쁨', '기쁨', '기쁨', '상처', '당황', '불안', '상처', '상처', '상처', '상처', '상처', '상처', '기쁨', '상처', '상처', '당황', '분노', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '불안', '슬픔', '당황', '슬픔', '슬픔', '슬픔', '분노', '기쁨', '분노', '불안', '분노', '분노', '분노', '분노', '상처', '분노', '불안', '당황', '분노', '불안', '당황', '불안', '분노', '상처', '분노', '불안', '당황', '불안', '불안', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '상처', '분노', '불안', '상처', '분노', '분노', '분노', '기쁨', '분노', '분노', '분노', '분노', '분노', '분노', '상처', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '기쁨', '상처', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '당황', '당황', '당황', '당황', '당황', '당황', '분노', '당황', '당황', '당황', '당황', '당황', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '슬픔', '슬픔', '슬픔', '분노', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '불안', '불안', '상처', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '상처', '기쁨', '기쁨', '기쁨', '상처', '기쁨', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '분노', '상처', '상처', '상처', '상처', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '분노', '불안', '불안', '당황', '불안', '상처', '불안', '불안', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '기쁨', '당황', '당황', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '기쁨', '기쁨', '기쁨', '슬픔', '분노', '분노', '분노', '분노', '분노', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '상처', '분노', '상처', '상처', '상처', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '상처', '상처', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '분노', '상처', '기쁨', '기쁨', '슬픔', '슬픔', '상처', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '분노', '분노', '분노', '분노', '분노', '상처', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '분노', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '상처', '분노', '분노', '분노', '분노', '당황', '당황', '당황', '당황', '불안', '불안', '불안', '불안', '당황', '기쁨', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '당황', '기쁨', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '상처', '분노', '불안', '당황', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '당황', '기쁨', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '기쁨', '기쁨', '기쁨', '기쁨', '불안', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '기쁨', '상처', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '불안', '불안', '불안', '불안', '불안', '당황', '당황', '불안', '불안', '불안', '상처', '상처', '분노', '불안', '불안', '불안', '불안', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '분노', '불안', '분노', '분노', '상처', '분노', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '기쁨', '기쁨', '기쁨', '상처', '불안', '상처', '상처', '상처', '슬픔', '슬픔', '당황', '당황', '분노', '불안', '불안', '불안', '당황', '당황', '기쁨', '당황', '당황', '기쁨', '기쁨', '분노', '기쁨', '상처', '기쁨', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '당황', '당황', '분노', '분노', '기쁨', '기쁨', '기쁨', '분노', '상처', '당황', '기쁨', '당황', '당황', '당황', '불안', '당황', '당황', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '상처', '상처', '불안', '불안', '분노', '분노', '상처', '상처', '상처', '분노', '당황', '분노', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '상처', '상처', '분노', '당황', '당황', '당황', '당황', '분노', '당황', '분노', '분노', '당황', '당황', '분노', '분노', '분노', '분노', '상처', '당황', '상처', '슬픔', '슬픔', '기쁨', '기쁨', '상처', '상처', '불안', '기쁨', '상처', '불안', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '불안', '당황', '당황', '당황', '당황', '분노', '당황', '당황', '당황', '분노', '당황', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '불안', '상처', '당황', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '기쁨', '당황', '당황', '슬픔', '기쁨', '기쁨', '불안', '기쁨', '기쁨', '기쁨', '기쁨', '상처', '분노', '상처', '분노', '분노', '상처', '슬픔', '슬픔', '당황', '슬픔', '당황', '당황', '당황', '당황', '당황', '당황', '불안', '당황', '당황', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '상처', '당황', '분노', '분노', '분노', '분노', '분노', '상처', '당황', '당황', '당황', '당황', '상처', '당황', '당황', '당황', '당황', '당황', '상처', '분노', '분노', '상처', '분노', '상처', '상처', '분노', '상처', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '상처', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '상처', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '불안', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '분노', '기쁨', '당황', '분노', '불안', '당황', '불안', '불안', '불안', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '기쁨', '슬픔', '슬픔', '슬픔', '분노', '슬픔', '슬픔', '슬픔', '슬픔', '기쁨', '슬픔', '불안', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '상처', '기쁨', '기쁨', '당황', '불안', '불안', '불안', '당황', '당황', '슬픔', '슬픔', '슬픔', '슬픔', '불안', '불안', '불안', '불안', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '불안', '불안', '슬픔', '불안', '불안', '불안', '불안', '불안', '불안', '상처', '당황', '당황', '당황', '당황', '슬픔', '슬픔', '불안', '상처', '기쁨', '기쁨', '불안', '당황', '당황', '불안', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '상처', '당황', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '분노', '상처', '상처', '상처', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '분노', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '분노', '슬픔', '슬픔', '슬픔', '슬픔', '기쁨', '기쁨', '기쁨', '분노', '불안', '상처', '분노', '불안', '기쁨', '당황', '불안', '불안', '불안', '불안', '불안', '당황', '분노', '상처', '불안', '불안', '불안', '상처', '불안', '불안', '불안', '불안', '불안', '기쁨', '불안', '불안', '불안', '상처', '분노', '분노', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '기쁨', '기쁨', '분노', '상처', '상처', '분노', '분노', '당황', '분노', '상처', '상처', '상처', '당황', '당황', '당황', '상처', '기쁨', '당황', '당황', '당황', '분노', '상처', '분노', '당황', '불안', '당황', '상처', '당황', '분노', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '불안', '상처', '상처', '상처', '상처', '상처', '당황', '당황', '당황', '기쁨', '당황', '당황', '기쁨', '당황', '기쁨', '기쁨', '분노', '상처', '상처', '분노', '분노', '불안', '상처', '당황', '불안', '기쁨', '분노', '불안', '분노', '불안', '상처', '불안', '분노', '당황', '분노', '상처', '분노', '불안', '상처', '기쁨', '상처', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '기쁨', '상처', '기쁨', '기쁨', '상처', '기쁨', '기쁨', '슬픔', '기쁨', '기쁨', '기쁨', '상처', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '기쁨', '당황', '당황', '상처', '불안', '기쁨', '당황', '불안', '불안', '불안', '분노', '불안', '불안', '당황', '상처', '기쁨', '당황', '당황', '당황', '분노', '분노', '당황', '당황', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '당황', '당황', '당황', '기쁨', '기쁨', '기쁨', '당황', '당황', '기쁨', '당황', '기쁨', '당황', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '기쁨', '상처', '기쁨', '분노', '불안', '상처', '분노', '상처', '불안', '분노', '불안', '분노', '분노', '상처', '분노', '분노', '분노', '분노', '불안', '불안', '불안', '분노', '불안', '분노', '불안', '불안', '상처', '불안', '상처', '불안', '불안', '불안', '불안', '불안', '불안', '기쁨', '불안', '분노', '상처', '분노', '기쁨', '기쁨', '분노', '기쁨', '분노', '상처', '상처', '상처', '상처', '상처', '불안', '상처', '상처', '분노', '상처', '상처', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '분노', '상처', '슬픔', '슬픔', '슬픔', '슬픔', '불안', '불안', '당황', '기쁨', '당황', '당황', '당황', '당황', '당황', '상처', '분노', '분노', '상처', '분노', '분노', '불안', '분노', '불안', '불안', '당황', '당황', '기쁨', '불안', '당황', '기쁨', '기쁨', '당황', '상처', '당황', '당황', '당황', '당황', '분노', '불안', '불안', '당황', '분노', '당황', '불안', '불안', '상처', '분노', '불안', '불안', '불안', '불안', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '분노', '슬픔', '기쁨', '슬픔', '상처', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '기쁨', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '기쁨', '불안', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '상처', '상처', '당황', '당황', '분노', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '분노', '분노', '당황', '불안', '분노', '불안', '기쁨', '분노', '상처', '분노', '상처', '분노', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '불안', '당황', '불안', '불안', '불안', '분노', '기쁨', '불안', '불안', '상처', '불안', '불안', '불안', '불안', '불안', '상처', '불안', '기쁨', '당황', '당황', '당황', '당황', '당황', '당황', '기쁨', '당황', '당황', '분노', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '불안', '당황', '불안', '불안', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '기쁨', '기쁨', '상처', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '상처', '상처', '상처', '당황', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '당황', '당황', '기쁨', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '분노', '분노', '분노', '분노', '분노', '당황', '당황', '당황', '분노', '기쁨', '분노', '분노', '분노', '슬픔', '분노', '당황', '분노', '분노', '분노', '분노', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '분노', '분노', '불안', '상처', '분노', '당황', '당황', '당황', '당황', '당황', '분노', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '불안', '불안', '불안', '불안', '불안', '상처', '불안', '불안', '불안', '불안', '불안', '상처', '당황', '불안', '당황', '당황', '당황', '당황', '당황', '당황', '상처', '불안', '당황', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '당황', '당황', '당황', '당황', '불안', '당황', '당황', '당황', '당황', '당황', '당황', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '불안', '불안', '불안', '기쁨', '불안', '불안', '불안', '당황', '불안', '불안', '불안', '분노', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '분노', '분노', '분노', '분노', '분노', '분노', '불안', '분노', '분노', '분노', '분노', '분노', '당황', '당황', '당황', '기쁨', '당황', '분노', '당황', '당황', '상처', '상처', '당황', '당황', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '분노', '불안', '분노', '분노', '상처', '상처', '불안', '상처', '상처', '상처', '상처', '상처', '당황', '상처', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '불안', '분노', '분노', '슬픔', '슬픔', '슬픔', '슬픔', '불안', '불안', '불안', '불안', '상처', '불안', '불안', '당황', '불안', '상처', '불안', '불안', '당황', '불안', '불안', '불안', '상처', '불안', '분노', '당황', '당황', '당황', '기쁨', '당황', '당황', '기쁨', '상처', '분노', '분노', '분노', '분노', '분노', '상처', '분노', '분노', '분노', '분노', '불안', '분노', '분노', '상처', '상처', '불안', '불안', '당황', '불안', '불안', '불안', '기쁨', '당황', '당황', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '당황', '분노', '불안', '분노', '분노', '분노', '상처', '불안', '기쁨', '상처', '불안', '슬픔', '분노', '기쁨', '당황', '당황', '당황', '분노', '분노', '당황', '당황', '불안', '당황', '당황', '당황', '당황', '당황', '슬픔', '슬픔', '슬픔', '슬픔', '기쁨', '기쁨', '불안', '분노', '분노', '기쁨', '기쁨', '기쁨', '기쁨', '슬픔', '당황', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '불안', '상처', '분노', '상처', '상처', '분노', '분노', '분노', '기쁨', '당황', '분노', '분노', '분노', '분노', '분노', '분노', '상처', '불안', '분노', '분노', '불안', '당황', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '상처', '상처', '상처', '상처', '상처', '기쁨', '상처', '상처', '불안', '분노', '분노', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '상처', '기쁨', '기쁨', '기쁨', '분노', '분노', '분노', '분노', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '상처', '불안', '불안', '당황', '상처', '상처', '기쁨', '기쁨', '기쁨', '기쁨', '상처', '기쁨', '불안', '불안', '기쁨', '상처', '불안', '당황', '불안', '당황', '불안', '불안', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '분노', '기쁨', '불안', '불안', '불안', '불안', '당황', '불안', '분노', '불안', '불안', '상처', '기쁨', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '분노', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '불안', '불안', '분노', '분노', '분노', '분노', '분노', '분노', '당황', '슬픔', '슬픔', '슬픔', '슬픔', '분노', '상처', '상처', '당황', '상처', '상처', '상처', '불안', '불안', '불안', '불안', '기쁨', '분노', '상처', '상처', '불안', '불안', '불안', '분노', '분노', '상처', '불안', '불안', '불안', '분노', '불안', '당황', '분노', '당황', '분노', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '당황', '불안', '불안', '불안', '불안', '당황', '분노', '당황', '당황', '당황', '당황', '기쁨', '기쁨', '당황', '당황', '기쁨', '기쁨', '불안', '불안', '기쁨', '불안', '상처', '불안', '슬픔', '불안', '분노', '상처', '상처', '불안', '불안', '불안', '불안', '기쁨', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '당황', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '기쁨', '상처', '분노', '분노', '불안', '당황', '상처', '상처', '불안', '불안', '상처', '불안', '당황', '불안', '당황', '당황', '불안', '불안', '상처', '불안', '당황', '당황', '당황', '당황', '슬픔', '분노', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '분노', '당황', '분노', '당황', '당황', '분노', '당황', '분노', '분노', '분노', '상처', '분노', '기쁨', '상처', '상처', '기쁨', '기쁨', '기쁨', '당황', '불안', '상처', '상처', '기쁨', '상처', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '당황', '불안', '기쁨', '당황', '불안', '불안', '불안', '불안', '상처', '불안', '기쁨', '불안', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '불안', '분노', '기쁨', '기쁨', '분노', '당황', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '불안', '상처', '불안', '상처', '불안', '불안', '불안', '불안', '불안', '기쁨', '불안', '불안', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '당황', '당황', '당황', '당황', '당황', '불안', '당황', '당황', '당황', '당황', '당황', '당황', '기쁨', '당황', '불안', '당황', '기쁨', '분노', '상처', '당황', '분노', '기쁨', '상처', '기쁨', '당황', '당황', '당황', '당황', '상처', '당황', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '당황', '당황', '당황', '당황', '상처', '기쁨', '기쁨', '당황', '당황', '당황', '당황', '당황', '기쁨', '기쁨', '불안', '상처', '기쁨', '기쁨', '기쁨', '기쁨', '분노', '당황', '기쁨', '기쁨', '상처', '기쁨', '상처', '불안', '슬픔', '슬픔', '상처', '불안', '상처', '상처', '상처', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '분노', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '당황', '상처', '당황', '당황', '불안', '당황', '당황', '당황', '불안', '당황', '당황', '당황', '당황', '불안', '상처', '상처', '불안', '상처', '분노', '분노', '상처', '분노', '분노', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '상처', '상처', '상처', '기쁨', '상처', '불안', '상처', '불안', '분노', '당황', '상처', '상처', '상처', '상처', '상처', '기쁨', '상처', '상처', '상처', '상처', '분노', '상처', '상처', '상처', '불안', '불안', '불안', '불안', '불안', '불안', '분노', '기쁨', '불안', '상처', '상처', '불안', '기쁨', '상처', '상처', '당황', '불안', '불안', '분노', '불안', '불안', '상처', '상처', '불안', '불안', '불안', '불안', '불안', '분노', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '당황', '불안', '불안', '불안', '불안', '분노', '불안', '불안', '불안', '불안', '불안', '불안', '상처', '당황', '불안', '당황', '기쁨', '상처', '상처', '기쁨', '상처', '당황', '상처', '상처', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '불안', '당황', '당황', '불안', '불안', '상처', '기쁨', '상처', '불안', '상처', '기쁨', '기쁨', '상처', '불안', '기쁨', '불안', '기쁨', '분노', '당황', '분노', '분노', '분노', '상처', '기쁨', '상처', '상처', '불안', '분노', '상처', '상처', '상처', '상처', '당황', '당황', '당황', '기쁨', '상처', '당황', '당황', '상처', '분노', '분노', '기쁨', '분노', '분노', '기쁨', '분노', '상처', '기쁨', '분노', '분노', '분노', '상처', '분노', '당황', '불안', '분노', '분노', '불안', '분노', '불안', '불안', '분노', '분노', '분노', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '분노', '상처', '상처', '당황', '상처', '분노', '분노', '분노', '분노', '상처', '분노', '분노', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '분노', '분노', '분노', '분노', '기쁨', '분노', '상처', '기쁨', '상처', '분노', '불안', '분노', '분노', '기쁨', '분노', '당황', '불안', '당황', '당황', '분노', '당황', '상처', '상처', '상처', '상처', '상처', '상처', '불안', '기쁨', '당황', '불안', '불안', '불안', '분노', '상처', '상처', '기쁨', '불안', '당황', '불안', '당황', '상처', '당황', '당황', '분노', '상처', '당황', '당황', '불안', '상처', '기쁨', '상처', '분노', '분노', '상처', '기쁨', '상처', '상처', '불안', '불안', '불안', '분노', '기쁨', '상처', '상처', '분노', '상처', '기쁨', '슬픔', '상처', '상처', '상처', '분노', '상처', '상처', '상처', '상처', '불안', '불안', '불안', '불안', '불안', '상처', '분노', '상처', '기쁨', '상처', '상처', '당황', '불안', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '분노', '분노', '당황', '분노', '분노', '상처', '분노', '분노', '상처', '분노', '기쁨', '상처', '상처', '당황', '당황', '분노', '불안', '슬픔', '슬픔', '슬픔', '슬픔', '당황', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '당황', '슬픔', '슬픔', '슬픔', '당황', '슬픔', '슬픔', '슬픔', '당황', '상처', '당황', '불안', '당황', '당황', '당황', '상처', '상처', '상처', '기쁨', '불안', '불안', '분노', '불안', '당황', '상처', '불안', '상처', '상처', '기쁨', '분노', '분노', '상처', '기쁨', '불안', '분노', '상처', '불안', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '기쁨', '당황', '당황', '당황', '당황', '당황', '당황', '상처', '불안', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '불안', '불안', '불안', '상처', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '상처', '상처', '상처', '상처', '상처', '기쁨', '상처', '상처', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '상처', '불안', '불안', '슬픔', '슬픔', '당황', '당황', '당황', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '당황', '당황', '당황', '당황', '당황', '분노', '당황', '당황', '당황', '상처', '분노', '상처', '분노', '상처', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '슬픔', '불안', '상처', '분노', '슬픔', '기쁨', '상처', '상처', '불안', '상처', '상처', '상처', '상처', '상처', '상처', '분노', '분노', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '불안', '상처', '상처', '상처', '기쁨', '분노', '분노', '기쁨', '기쁨', '기쁨', '상처', '분노', '불안', '상처', '상처', '상처', '분노', '당황', '상처', '분노', '상처', '슬픔', '슬픔', '분노', '불안', '기쁨', '기쁨', '불안', '상처', '슬픔', '기쁨', '기쁨', '기쁨', '분노', '기쁨', '상처', '분노', '불안', '분노', '상처', '불안', '상처', '당황', '분노', '당황', '당황', '상처', '당황', '불안', '분노', '분노', '분노', '분노', '불안', '불안', '불안', '분노', '불안', '불안', '불안', '당황', '당황', '불안', '불안', '슬픔', '기쁨', '분노', '슬픔', '불안', '슬픔', '상처', '상처', '분노', '분노', '당황', '당황', '상처', '분노', '기쁨', '상처', '불안', '당황', '불안', '불안', '불안', '불안', '불안', '불안', '당황', '불안', '불안', '상처', '상처', '상처', '당황', '불안', '당황', '슬픔', '상처', '불안', '상처', '불안', '상처', '상처', '기쁨', '당황', '분노', '분노', '분노', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '상처', '당황', '상처', '불안', '당황', '슬픔', '슬픔', '슬픔', '슬픔', '기쁨', '기쁨', '기쁨', '분노', '분노', '불안', '불안', '분노', '불안', '당황', '기쁨', '상처', '기쁨', '기쁨', '불안', '불안', '당황', '당황', '분노', '상처', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '분노', '불안', '분노', '당황', '상처', '상처', '기쁨', '상처', '상처', '상처', '불안', '불안', '불안', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '불안', '상처', '분노', '불안', '분노', '분노', '분노', '분노', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '분노', '분노', '상처', '불안', '분노', '분노', '분노', '분노', '분노', '분노', '불안', '불안', '당황', '상처', '불안', '분노', '분노', '당황', '상처', '분노', '당황', '불안', '슬픔', '슬픔', '슬픔', '기쁨', '기쁨', '분노', '기쁨', '기쁨', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '불안', '불안', '당황', '불안', '기쁨', '기쁨', '당황', '기쁨', '기쁨', '기쁨', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '상처', '불안', '상처', '분노', '불안', '상처', '상처', '기쁨', '상처', '상처', '상처', '분노', '상처', '상처', '상처', '상처', '상처', '상처', '불안', '불안', '불안', '불안', '분노', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '기쁨', '당황', '당황', '당황', '당황', '상처', '당황', '당황', '당황', '당황', '당황', '기쁨', '분노', '당황', '분노', '분노', '분노', '분노', '분노', '분노', '분노', '불안', '당황', '당황', '불안', '불안', '상처', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '기쁨', '슬픔', '불안', '기쁨', '기쁨', '상처', '상처', '불안', '분노', '분노', '분노', '분노', '슬픔', '슬픔', '상처', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '불안', '당황', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '당황', '슬픔', '기쁨', '슬픔', '슬픔', '당황', '당황', '당황', '당황', '슬픔', '상처', '상처', '상처', '기쁨', '불안', '기쁨', '기쁨', '불안', '분노', '상처', '당황', '상처', '분노', '상처', '분노', '기쁨', '당황', '불안', '기쁨', '상처', '불안', '상처', '상처', '슬픔', '슬픔', '슬픔', '상처', '당황', '기쁨', '상처', '기쁨', '기쁨', '불안', '당황', '상처', '불안', '슬픔', '슬픔', '기쁨', '기쁨', '불안', '분노', '상처', '기쁨', '기쁨', '분노', '상처', '분노', '상처', '분노', '기쁨', '슬픔', '기쁨', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '불안', '기쁨', '불안', '기쁨', '기쁨', '기쁨', '슬픔', '슬픔', '기쁨', '슬픔', '상처', '기쁨', '당황', '당황', '분노', '기쁨', '기쁨', '기쁨', '분노', '상처', '당황', '불안', '상처', '분노', '기쁨', '슬픔', '당황', '기쁨', '기쁨', '당황', '분노', '상처', '당황', '기쁨', '기쁨', '기쁨', '기쁨', '불안', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '슬픔', '기쁨', '기쁨', '기쁨', '당황', '상처', '상처', '불안', '상처', '상처', '상처', '상처', '상처', '기쁨', '상처', '상처', '상처', '분노', '기쁨', '기쁨', '기쁨', '불안', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '분노', '기쁨', '기쁨', '기쁨', '불안', '기쁨', '기쁨', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '상처', '상처', '분노', '분노', '상처', '분노', '분노', '분노', '당황', '분노', '상처', '당황', '분노', '당황', '당황', '불안', '당황', '분노', '당황', '당황', '불안', '당황', '당황', '당황', '분노', '기쁨', '불안', '당황', '기쁨', '분노', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '기쁨', '불안', '상처', '상처', '당황', '분노', '분노', '불안', '불안', '분노', '상처', '불안', '당황', '당황', '기쁨', '불안', '불안', '불안', '슬픔', '상처', '슬픔', '분노', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '상처', '분노', '분노', '분노', '불안', '상처', '기쁨', '당황', '불안', '불안', '슬픔', '분노', '상처', '당황', '상처', '상처', '분노', '분노', '불안', '당황', '상처', '당황', '분노', '당황', '기쁨', '기쁨', '당황', '당황', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '상처', '불안', '분노', '분노', '분노', '분노', '분노', '분노', '기쁨', '불안', '기쁨', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '분노', '분노', '상처', '상처', '상처', '상처', '기쁨', '당황', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '분노', '분노', '상처', '상처', '분노', '불안', '분노', '분노', '분노', '분노', '상처', '불안', '상처', '분노', '상처', '상처', '상처', '상처', '상처', '불안', '상처', '기쁨', '상처', '불안', '분노', '불안', '당황', '분노', '분노', '상처', '불안', '분노', '기쁨', '불안', '상처', '상처', '불안', '기쁨', '기쁨', '기쁨', '불안', '분노', '기쁨', '기쁨', '기쁨', '분노', '불안', '기쁨', '분노', '분노', '기쁨', '분노', '불안', '불안', '상처', '분노', '불안', '상처', '불안', '상처', '분노', '분노', '분노', '상처', '상처', '상처', '당황', '불안', '불안', '불안', '불안', '당황', '슬픔', '분노', '당황', '분노', '불안', '분노', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '불안', '불안', '슬픔', '슬픔', '슬픔', '슬픔', '상처', '불안', '불안', '기쁨', '불안', '당황', '분노', '불안', '기쁨', '분노', '상처', '상처', '분노', '분노', '슬픔', '분노', '기쁨', '상처', '불안', '기쁨', '불안', '불안', '불안', '불안', '불안', '상처', '분노', '상처', '분노', '상처', '상처', '불안', '불안', '상처', '상처', '상처', '상처', '상처', '불안', '상처', '상처', '분노', '기쁨', '분노', '불안', '상처', '상처', '분노', '불안', '불안', '상처', '불안', '당황', '불안', '분노', '불안', '분노', '당황', '당황', '분노', '분노', '불안', '불안', '불안', '불안', '당황', '불안', '상처', '불안', '분노', '불안', '당황', '불안', '불안', '불안', '상처', '기쁨', '기쁨', '당황', '불안', '상처', '기쁨', '불안', '불안', '기쁨', '기쁨', '당황', '기쁨', '분노', '분노', '분노', '분노', '기쁨', '불안', '상처', '상처', '상처', '기쁨', '상처', '상처', '불안', '불안', '상처', '기쁨', '불안', '불안', '상처', '상처', '슬픔', '슬픔', '슬픔', '기쁨', '슬픔', '슬픔', '기쁨', '슬픔', '슬픔', '기쁨', '당황', '당황', '당황', '당황', '당황', '당황', '분노', '분노', '당황', '분노', '상처', '불안', '불안', '상처', '불안', '상처', '불안', '불안', '기쁨', '불안', '분노', '분노', '상처', '분노', '상처', '불안', '분노', '불안', '불안', '분노', '불안', '당황', '분노', '분노', '분노', '불안', '상처', '상처', '당황', '슬픔', '당황', '불안', '당황', '당황', '당황', '기쁨', '당황', '당황', '상처', '상처', '당황', '분노', '분노', '분노', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '당황', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '당황', '불안', '상처', '불안', '당황', '상처', '분노', '상처', '상처', '상처', '상처', '상처', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '불안', '당황', '불안', '분노', '불안', '불안', '분노', '당황', '불안', '슬픔', '상처', '불안', '상처', '불안', '불안', '분노', '분노', '당황', '분노', '불안', '상처', '상처', '상처', '불안', '상처', '불안', '불안', '상처', '상처', '상처', '상처', '상처', '상처', '불안', '분노', '상처', '상처', '분노', '당황', '기쁨', '기쁨', '기쁨', '기쁨', '분노', '분노', '슬픔', '분노', '분노', '분노', '분노', '분노', '분노', '슬픔', '슬픔', '슬픔', '슬픔', '분노', '분노', '분노', '상처', '분노', '분노', '분노', '분노', '분노', '기쁨', '당황', '불안', '불안', '당황', '당황', '당황', '기쁨', '분노', '상처', '당황', '당황', '당황', '당황', '기쁨', '상처', '상처', '상처', '분노', '당황', '상처', '당황', '상처', '불안', '불안', '불안', '불안', '불안', '불안', '분노', '불안', '분노', '분노', '슬픔', '상처', '슬픔', '슬픔', '슬픔', '분노', '상처', '상처', '기쁨', '당황', '불안', '기쁨', '분노', '기쁨', '슬픔', '슬픔', '불안', '불안', '불안', '기쁨', '기쁨', '기쁨', '당황', '슬픔', '기쁨', '기쁨', '불안', '기쁨', '당황', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '불안', '불안', '불안', '슬픔', '슬픔', '슬픔', '당황', '슬픔', '분노', '기쁨', '당황', '슬픔', '슬픔', '슬픔', '분노', '슬픔', '상처', '상처', '당황', '기쁨', '불안', '불안', '당황', '불안', '상처', '분노', '분노', '당황', '당황', '상처', '당황', '기쁨', '상처', '상처', '분노', '상처', '상처', '불안', '당황', '당황', '상처', '기쁨', '기쁨', '당황', '분노', '슬픔', '슬픔', '분노', '기쁨', '분노', '분노', '불안', '기쁨', '불안', '당황', '당황', '당황', '당황', '불안', '불안', '당황', '분노', '상처', '상처', '기쁨', '당황', '상처', '기쁨', '당황', '슬픔', '슬픔', '분노', '슬픔', '슬픔', '슬픔', '불안', '당황', '불안', '기쁨', '분노', '분노', '분노', '불안', '기쁨', '상처', '불안', '당황', '상처', '상처', '상처', '상처', '상처', '상처', '불안', '당황', '기쁨', '상처', '불안', '기쁨', '분노', '슬픔', '불안', '슬픔', '슬픔', '슬픔', '슬픔', '당황', '상처', '분노', '기쁨', '상처', '상처', '기쁨', '기쁨', '분노', '슬픔', '슬픔', '슬픔', '당황', '슬픔', '불안', '당황', '상처', '상처', '분노', '분노', '분노', '당황', '분노', '불안', '당황', '기쁨', '상처', '당황', '기쁨', '상처', '분노', '상처', '상처', '불안', '불안', '불안', '분노', '기쁨', '기쁨', '기쁨', '기쁨', '당황', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '불안', '상처', '불안', '당황', '불안', '상처', '불안', '분노', '당황', '당황', '당황', '기쁨', '당황', '분노', '당황', '상처', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '당황', '상처', '분노', '상처', '상처', '상처', '상처', '분노', '기쁨', '기쁨', '분노', '기쁨', '기쁨', '당황', '슬픔', '슬픔', '당황', '슬픔', '슬픔', '불안', '슬픔', '상처', '불안', '분노', '당황', '당황', '당황', '당황', '당황', '당황', '상처', '상처', '상처', '불안', '불안', '분노', '분노', '기쁨', '분노', '상처', '슬픔', '슬픔', '당황', '슬픔', '불안', '슬픔', '분노', '슬픔', '불안', '불안', '상처', '불안', '불안', '분노', '불안', '불안', '기쁨', '분노', '분노', '분노', '상처', '분노', '기쁨', '분노', '당황', '불안', '불안', '분노', '불안', '불안', '슬픔', '슬픔', '슬픔', '슬픔', '당황', '슬픔', '불안', '분노', '상처', '불안', '불안', '분노', '상처', '불안', '불안', '기쁨', '분노', '당황', '당황', '분노', '분노', '상처', '불안', '상처', '상처', '상처', '분노', '분노', '불안', '상처', '슬픔', '분노', '슬픔', '슬픔', '불안', '슬픔', '슬픔', '슬픔', '상처', '상처', '불안', '불안', '당황', '분노', '기쁨', '불안', '분노', '기쁨', '슬픔', '당황', '기쁨', '당황', '불안', '상처', '상처', '당황', '당황', '상처', '상처', '슬픔', '슬픔', '기쁨', '슬픔', '슬픔', '상처', '불안', '불안', '분노', '불안', '분노', '분노', '상처', '당황', '당황', '당황', '상처', '당황', '기쁨', '당황', '상처', '상처', '분노', '불안', '당황', '상처', '슬픔', '상처', '슬픔', '불안', '슬픔', '슬픔', '당황', '상처', '당황', '기쁨', '불안', '슬픔', '당황', '슬픔', '슬픔', '불안', '분노', '당황', '상처', '불안', '분노', '불안', '불안', '당황', '분노', '당황', '당황', '불안', '당황', '상처', '상처', '기쁨', '분노', '분노', '기쁨', '슬픔', '슬픔', '슬픔', '불안', '불안', '당황', '기쁨', '상처', '불안', '상처', '기쁨', '불안', '분노', '슬픔', '당황', '분노', '당황', '당황', '기쁨', '기쁨', '기쁨', '불안', '슬픔', '슬픔', '당황', '상처', '기쁨', '슬픔', '당황', '상처', '상처', '불안', '상처', '분노', '불안', '당황', '기쁨', '당황', '당황', '상처', '상처', '상처', '상처', '상처', '기쁨', '상처', '기쁨', '기쁨', '불안', '슬픔', '상처', '당황', '분노', '상처', '상처', '분노', '상처', '상처', '불안', '분노', '기쁨', '기쁨', '슬픔', '슬픔', '슬픔', '슬픔', '상처', '슬픔', '불안', '불안', '상처', '기쁨', '분노', '슬픔', '당황', '당황', '당황', '당황', '분노', '불안', '기쁨', '분노', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '상처', '분노', '분노', '상처', '분노', '당황', '당황', '분노', '당황', '당황', '상처', '분노', '상처', '불안', '기쁨', '기쁨', '슬픔', '불안', '당황', '분노', '불안', '기쁨', '당황', '기쁨', '분노', '슬픔', '당황', '슬픔', '불안', '슬픔', '분노', '슬픔', '불안', '당황', '분노', '불안', '당황', '분노', '불안', '상처', '불안', '분노', '기쁨', '슬픔', '슬픔', '상처', '분노', '상처', '당황', '당황', '분노', '슬픔', '불안', '기쁨', '슬픔', '상처', '분노', '슬픔', '당황', '슬픔', '분노', '분노', '분노', '분노', '불안', '상처', '불안', '슬픔', '슬픔', '불안', '분노', '불안', '상처', '슬픔', '상처', '상처', '당황', '불안', '기쁨', '기쁨', '당황', '불안', '분노', '당황', '상처', '상처', '슬픔', '슬픔', '기쁨', '당황', '분노', '불안', '당황', '상처', '분노', '분노', '당황', '분노', '상처', '당황', '상처', '기쁨', '슬픔', '기쁨', '슬픔', '분노', '슬픔', '불안', '불안', '당황', '상처', '상처', '슬픔', '당황', '상처', '슬픔', '불안', '슬픔', '불안', '분노', '기쁨', '슬픔', '당황', '상처', '불안', '당황', '슬픔', '슬픔', '분노', '슬픔', '슬픔', '당황', '당황', '당황', '불안', '불안', '기쁨', '불안', '분노', '분노', '당황', '기쁨', '불안', '당황', '불안', '기쁨', '기쁨', '상처', '불안', '분노', '상처', '상처', '당황', '당황', '상처', '불안', '상처', '기쁨', '기쁨', '슬픔', '분노', '분노', '슬픔', '슬픔', '불안', '분노', '분노', '불안', '슬픔', '상처', '슬픔', '슬픔', '슬픔', '슬픔', '불안', '불안', '불안', '상처', '분노', '분노', '기쁨', '당황', '상처', '당황', '불안', '당황', '상처', '불안', '분노', '슬픔', '불안', '슬픔', '슬픔', '불안', '불안', '분노', '상처', '상처', '불안', '당황', '당황', '분노', '당황', '불안', '기쁨', '슬픔', '분노', '상처', '불안', '분노', '분노', '당황', '당황', '기쁨', '슬픔', '불안', '상처', '슬픔', '슬픔', '슬픔', '기쁨', '분노', '당황', '불안', '당황', '분노', '기쁨', '상처', '슬픔', '불안', '기쁨', '상처', '상처', '불안', '분노', '당황', '상처', '분노', '당황', '상처', '슬픔', '슬픔', '불안', '당황', '상처', '상처', '기쁨', '상처', '불안', '불안', '기쁨', '당황', '상처', '당황', '불안', '불안', '상처', '상처', '당황', '불안', '기쁨', '불안', '상처', '상처', '상처', '슬픔', '상처', '기쁨', '슬픔', '분노', '불안', '상처', '불안', '당황', '기쁨', '불안', '불안', '분노', '당황', '불안', '슬픔', '상처', '슬픔', '상처', '기쁨', '당황', '슬픔', '불안', '불안', '불안', '상처', '당황', '상처', '상처', '상처', '분노', '기쁨', '기쁨', '불안', '당황', '불안', '불안', '분노', '분노', '상처', '상처', '분노', '당황', '기쁨', '당황', '불안', '상처', '기쁨', '분노', '상처', '당황', '상처', '당황', '기쁨', '불안', '불안', '당황', '기쁨', '분노', '슬픔', '슬픔', '기쁨', '상처', '당황', '슬픔', '불안', '기쁨', '상처', '상처', '상처', '불안', '기쁨', '슬픔', '분노', '당황', '당황', '상처', '불안', '불안', '분노', '당황', '불안', '기쁨', '당황', '불안', '슬픔', '슬픔', '당황', '당황', '당황', '슬픔', '상처', '분노', '당황', '불안', '분노', '슬픔', '상처', '불안', '분노', '불안', '불안', '불안', '불안', '기쁨', '불안', '불안', '불안', '불안', '분노', '불안', '불안', '슬픔', '불안', '불안', '불안', '슬픔', '슬픔', '슬픔', '불안', '기쁨', '당황', '슬픔', '당황', '당황', '당황', '기쁨', '슬픔', '기쁨', '슬픔', '기쁨', '기쁨', '불안', '기쁨', '불안', '불안', '기쁨', '기쁨', '상처', '기쁨', '슬픔', '기쁨', '슬픔', '당황', '기쁨', '기쁨', '기쁨', '슬픔', '기쁨', '슬픔', '기쁨', '슬픔', '슬픔', '상처', '기쁨', '기쁨', '슬픔', '슬픔', '기쁨', '기쁨', '슬픔', '당황', '기쁨', '기쁨', '기쁨', '불안', '기쁨', '슬픔', '슬픔', '슬픔', '슬픔', '기쁨', '불안', '분노', '슬픔', '불안', '당황', '당황', '불안', '상처', '기쁨', '기쁨', '슬픔', '슬픔', '기쁨', '불안', '분노', '불안', '불안', '분노', '상처', '당황', '상처', '상처', '슬픔', '불안', '불안', '불안', '상처', '당황', '기쁨', '당황', '불안', '당황', '당황', '당황', '상처', '불안', '당황', '불안', '불안', '상처', '당황', '상처', '불안', '기쁨', '당황', '슬픔', '불안', '기쁨', '기쁨', '기쁨', '불안', '당황', '분노', '당황', '불안', '불안', '당황', '불안', '당황', '상처', '불안', '기쁨', '기쁨', '슬픔', '슬픔', '슬픔', '불안', '불안', '불안', '불안', '상처', '당황', '당황', '불안', '기쁨', '상처', '불안', '불안', '슬픔', '분노', '당황', '상처', '불안', '불안', '불안', '불안', '상처', '분노', '상처', '상처', '기쁨', '기쁨', '기쁨', '슬픔', '불안', '불안', '불안', '상처', '슬픔', '슬픔', '슬픔', '슬픔', '불안', '불안', '슬픔', '불안', '상처', '당황', '기쁨', '기쁨', '기쁨', '불안', '슬픔', '슬픔', '기쁨', '당황', '당황', '상처', '기쁨', '상처', '슬픔', '슬픔', '슬픔', '슬픔', '분노', '당황', '기쁨', '불안', '불안', '불안', '분노', '불안', '불안', '불안', '당황', '기쁨', '분노', '슬픔', '슬픔', '슬픔', '슬픔', '기쁨', '불안', '불안', '당황', '상처', '상처', '기쁨', '불안', '슬픔', '슬픔', '슬픔', '상처', '슬픔', '슬픔', '상처', '슬픔', '당황', '당황', '상처', '기쁨', '기쁨', '불안', '불안', '기쁨', '당황', '슬픔', '슬픔', '슬픔', '불안', '불안', '당황', '기쁨', '상처', '불안', '기쁨', '슬픔', '불안', '불안', '당황', '당황', '상처', '분노', '불안', '기쁨', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '분노', '기쁨', '상처', '불안', '상처', '상처', '상처', '당황', '기쁨', '기쁨', '기쁨', '기쁨', '슬픔', '당황', '상처', '기쁨', '분노', '당황', '상처', '당황', '불안', '불안', '슬픔', '슬픔', '분노', '불안', '당황', '불안', '상처', '기쁨', '당황', '슬픔', '불안', '슬픔', '분노', '상처', '불안', '당황', '상처', '당황', '불안', '당황', '슬픔', '분노', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '당황', '상처', '기쁨', '슬픔', '슬픔', '슬픔', '불안', '불안', '상처', '상처', '상처', '슬픔', '불안', '불안', '당황', '당황', '당황', '당황', '슬픔', '슬픔', '슬픔', '불안', '슬픔', '슬픔', '슬픔', '불안', '불안', '불안', '슬픔', '슬픔', '당황', '기쁨', '불안', '불안', '당황', '기쁨', '당황', '상처', '상처', '당황', '당황', '슬픔', '불안', '불안', '분노', '분노', '당황', '당황', '상처', '상처', '슬픔', '슬픔', '슬픔', '분노', '당황', '당황', '당황', '분노', '분노', '불안', '불안', '분노', '분노', '분노', '당황', '당황', '상처', '기쁨', '기쁨', '슬픔', '슬픔', '불안', '당황', '슬픔', '슬픔', '분노', '분노', '분노', '당황', '상처', '상처', '상처', '기쁨', '슬픔', '슬픔', '슬픔', '슬픔', '기쁨', '당황', '슬픔', '기쁨', '기쁨', '분노', '불안', '불안', '불안', '분노', '당황', '상처', '상처', '불안', '기쁨', '기쁨', '슬픔', '슬픔', '슬픔', '불안', '분노', '불안', '불안', '분노', '분노', '상처', '당황', '분노', '당황', '당황', '분노', '상처', '분노', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '기쁨', '기쁨', '기쁨', '상처', '기쁨', '분노', '기쁨', '기쁨', '기쁨', '분노', '기쁨', '불안', '기쁨', '상처', '상처', '상처', '기쁨', '슬픔', '슬픔', '당황', '불안', '당황', '당황', '분노', '분노', '분노', '기쁨', '당황', '당황', '상처', '상처', '상처', '기쁨', '분노', '기쁨', '기쁨', '슬픔', '슬픔', '슬픔', '슬픔', '불안', '불안', '불안', '상처', '불안', '분노', '분노', '분노', '분노', '당황', '상처', '당황', '상처', '상처', '상처', '기쁨', '기쁨', '기쁨', '기쁨', '불안', '기쁨', '기쁨', '기쁨', '기쁨', '기쁨', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '상처', '기쁨', '상처', '당황', '슬픔', '분노', '분노', '분노', '불안', '분노', '기쁨', '당황', '기쁨', '기쁨', '상처', '불안', '상처', '기쁨', '슬픔', '불안', '불안', '분노', '분노', '분노', '기쁨', '당황', '당황', '당황', '당황', '당황', '상처', '상처', '기쁨', '기쁨', '기쁨', '당황', '슬픔', '상처', '슬픔', '불안', '불안', '분노', '분노', '당황', '당황', '불안', '상처', '기쁨', '슬픔', '당황', '당황', '불안', '슬픔', '슬픔', '슬픔', '슬픔', '당황', '당황', '당황', '불안', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '상처', '불안', '당황', '당황', '당황', '당황', '상처', '상처', '기쁨', '슬픔', '슬픔', '슬픔', '슬픔', '분노', '불안', '분노', '당황', '당황', '상처', '상처', '상처', '슬픔', '슬픔', '슬픔', '당황', '당황', '상처', '기쁨', '불안', '불안', '분노', '분노', '불안', '상처', '기쁨', '상처', '기쁨', '기쁨', '기쁨', '기쁨', '슬픔', '분노', '불안', '불안', '불안', '상처', '불안', '분노', '상처', '분노', '분노', '분노', '당황', '상처', '당황', '당황', '분노', '상처', '상처', '불안', '상처', '기쁨', '슬픔', '분노', '불안', '불안', '불안', '분노', '상처', '분노', '분노', '분노', '상처', '상처', '기쁨', '기쁨', '불안', '기쁨', '기쁨', '당황', '당황', '당황', '슬픔', '슬픔', '분노', '슬픔', '상처', '불안', '기쁨', '슬픔', '슬픔', '슬픔', '분노', '분노', '슬픔', '슬픔', '분노', '슬픔', '불안', '당황', '기쁨', '불안', '불안', '분노', '슬픔', '불안', '불안', '불안', '상처', '당황', '상처', '기쁨', '상처', '슬픔', '당황', '기쁨', '슬픔', '슬픔', '분노', '당황', '상처', '기쁨', '불안', '상처', '기쁨', '당황', '슬픔', '상처', '상처', '슬픔', '불안', '분노', '기쁨', '기쁨', '기쁨', '슬픔', '슬픔', '슬픔', '상처', '불안', '슬픔', '슬픔', '분노', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '분노', '불안', '분노', '불안', '당황', '상처', '기쁨', '분노', '당황', '슬픔', '분노', '슬픔', '불안', '상처', '상처', '분노', '상처', '불안', '당황', '분노', '상처', '분노', '분노', '상처', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '슬픔', '당황', '불안', '상처', '상처', '분노', '불안', '당황', '분노', '기쁨', '상처', '슬픔', '슬픔', '슬픔', '슬픔', '기쁨', '불안', '불안', '불안', '분노', '불안', '불안', '상처', '분노', '당황', '분노', '당황', '상처', '상처', '분노', '불안', '상처', '상처', '슬픔', '슬픔', '슬픔', '상처', '불안', '상처', '슬픔', '분노', '분노', '불안', '분노', '불안', '분노', '상처', '당황', '상처', '당황', '불안', '상처', '분노', '슬픔', '불안', '불안', '상처', '슬픔', '기쁨', '슬픔', '불안', '당황', '분노', '불안', '불안', '분노', '분노', '슬픔', '분노', '당황', '분노', '슬픔', '당황', '당황', '상처', '상처', '불안', '상처', '상처', '상처', '당황', '당황', '기쁨', '당황', '당황', '기쁨', '슬픔', '슬픔', '불안', '당황', '분노', '상처', '상처', '상처', '상처', '불안', '당황', '상처', '상처', '분노', '분노', '기쁨', '상처', '분노', '불안', '상처', '불안', '불안', '기쁨', '분노', '기쁨', '분노', '기쁨', '분노', '기쁨', '상처', '분노', '불안', '불안', '상처', '상처', '분노', '불안', '불안', '슬픔', '불안', '상처', '상처', '기쁨', '슬픔', '상처', '당황', '상처', '상처', '분노', '불안', '분노', '기쁨', '기쁨', '상처', '슬픔', '분노', '슬픔', '분노', '당황', '불안', '당황', '슬픔', '상처', '불안', '분노', '당황', '슬픔', '상처', '분노', '슬픔', '당황', '불안', '불안', '불안', '슬픔', '기쁨', '불안', '상처', '당황', '불안', '당황', '불안', '기쁨', '상처', '불안', '분노', '분노', '당황', '상처', '불안', '슬픔', '불안', '당황', '분노', '당황', '슬픔', '기쁨', '기쁨', '분노', '기쁨', '기쁨', '분노', '분노', '불안', '불안', '분노', '슬픔', '분노', '당황', '당황', '상처', '상처', '상처', '분노', '상처', '불안', '상처', '슬픔', '당황', '분노', '기쁨', '슬픔', '당황', '상처', '분노', '기쁨', '당황', '상처', '슬픔', '상처', '분노', '상처', '불안', '슬픔', '불안', '상처', '슬픔', '상처', '분노', '당황', '분노', '슬픔', '분노', '분노', '불안', '당황', '분노', '상처', '불안', '기쁨', '상처', '분노', '불안', '불안', '분노', '슬픔', '상처', '불안', '당황', '당황', '당황', '당황', '슬픔', '불안', '분노', '불안', '불안', '당황', '슬픔', '슬픔', '당황', '당황', '분노', '불안', '상처', '당황', '당황', '불안', '슬픔', '당황', '당황', '불안', '불안', '불안', '슬픔', '상처', '분노', '슬픔', '상처', '슬픔', '분노', '슬픔', '불안', '당황', '불안', '분노', '당황', '불안', '불안', '당황', '슬픔', '당황', '당황', '불안', '슬픔', '슬픔', '분노', '상처', '상처', '당황', '불안', '불안', '불안', '당황', '불안', '기쁨', '당황', '불안', '기쁨', '기쁨', '상처', '분노', '당황', '상처', '불안', '슬픔', '당황', '불안', '기쁨', '슬픔', '분노', '기쁨', '당황', '상처', '상처', '당황', '불안', '기쁨', '기쁨', '상처', '불안', '불안', '분노', '분노', '기쁨', '기쁨', '슬픔', '분노', '불안', '상처', '슬픔', '슬픔', '슬픔', '상처', '당황', '상처', '당황', '불안', '불안', '분노', '불안', '당황', '당황', '기쁨', '기쁨', '기쁨', '당황', '슬픔', '기쁨', '기쁨', '불안', '불안', '슬픔', '슬픔', '기쁨', '상처', '불안', '상처', '기쁨', '분노', '당황', '기쁨', '상처', '불안', '상처', '분노', '당황', '상처', '상처', '분노', '불안', '분노', '상처', '불안', '당황', '상처', '분노', '슬픔', '기쁨', '슬픔', '당황', '슬픔', '슬픔', '기쁨', '당황', '불안', '당황', '당황', '당황', '불안', '슬픔', '상처', '슬픔', '불안', '상처', '상처', '상처', '슬픔', '슬픔', '기쁨', '분노', '기쁨', '슬픔', '불안', '불안', '당황', '상처', '분노', '기쁨', '분노', '슬픔', '분노', '분노', '기쁨', '기쁨', '슬픔', '기쁨', '기쁨', '슬픔', '분노', '분노', '분노', '불안', '기쁨', '슬픔', '분노', '기쁨', '불안', '당황', '상처', '기쁨', '슬픔', '분노', '불안', '분노', '불안', '상처', '불안', '분노', '당황', '슬픔', '분노', '상처', '당황', '상처', '불안', '슬픔', '상처', '상처', '분노', '분노', '기쁨', '기쁨', '기쁨', '상처', '불안', '당황', '상처', '분노', '불안', '기쁨', '상처', '당황', '상처', '상처', '분노', '분노', '슬픔', '분노', '당황', '상처', '당황', '슬픔', '당황', '불안', '상처', '분노', '슬픔', '당황', '상처', '상처', '분노', '슬픔', '기쁨', '분노', '분노', '기쁨', '분노', '불안', '슬픔', '불안', '분노', '불안', '기쁨', '슬픔', '상처', '슬픔', '상처', '불안', '기쁨', '상처', '당황', '슬픔', '당황', '기쁨', '상처', '상처', '분노', '상처', '상처', '불안', '슬픔', '상처', '슬픔', '상처', '분노', '기쁨', '분노', '기쁨', '상처', '기쁨', '슬픔', '당황', '기쁨', '분노', '기쁨', '상처', '당황', '슬픔', '기쁨', '슬픔', '불안', '당황', '기쁨', '상처', '불안', '불안', '기쁨', '슬픔', '상처', '불안', '상처', '상처', '불안', '슬픔', '슬픔', '불안', '불안', '상처', '당황', '상처', '기쁨', '기쁨', '상처', '불안', '분노', '당황', '불안', '분노', '불안', '기쁨', '상처', '분노', '당황', '불안', '슬픔', '상처', '기쁨', '불안', '분노', '상처', '기쁨', '슬픔', '상처', '상처', '슬픔', '상처', '불안', '슬픔', '슬픔', '분노', '상처', '기쁨', '당황', '슬픔', '슬픔', '기쁨', '불안', '분노', '불안', '불안', '불안', '분노', '슬픔', '불안', '슬픔', '슬픔', '상처', '상처', '상처', '당황', '분노', '슬픔', '상처', '기쁨', '기쁨', '상처', '불안', '불안', '당황', '당황', '슬픔', '슬픔', '슬픔', '기쁨', '불안', '슬픔', '기쁨', '슬픔', '상처', '상처', '상처', '상처', '상처', '슬픔', '불안', '상처', '기쁨']\n"
     ]
    }
   ],
   "source": [
    "# 예측 결과를 원래 태그로 변환\n",
    "predictions = model.predict(\n",
    "   {'input_ids':val_train['input_ids'],'attention_mask':val_train['attention_mask']})\n",
    "predicted_tags = np.argmax(predictions, axis=1)\n",
    "predicted_tags = [inverse_tag_mapping[tag] for tag in predicted_tags]\n",
    "\n",
    "print(\"Predicted Tags:\", predicted_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f775e4e6-15ad-4336-b3dd-49b913c8ef26",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m예측\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[43mpredictions\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "test[\"예측\"]=predicted_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4adc2709-a506-4f1c-84b9-b9a19f3742cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.08      0.07      1113\n",
      "           1       0.01      0.01      0.01      1003\n",
      "           2       0.09      0.09      0.09      1048\n",
      "           3       0.02      0.02      0.02      1213\n",
      "           4       0.08      0.07      0.07      1257\n",
      "           5       0.58      0.67      0.62      1007\n",
      "\n",
      "    accuracy                           0.15      6641\n",
      "   macro avg       0.14      0.16      0.15      6641\n",
      "weighted avg       0.13      0.15      0.14      6641\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 예측 결과와 실제 레이블을 가지고 classification report 생성\n",
    "y_true = val_data.감정_대분류_encoded\n",
    "y_pred =np.argmax(predictions, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65fbcc06-5e0f-47aa-acc0-c7c5e6d810f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./model/emotion/emotionkr_weights')\n",
    "model.save('./model/emotion/emotionkr.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a22ef4d4-ba92-4250-8a5c-b995acdbf1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = \"./bert_model_directory/klue_bert_base\"\n",
    "\n",
    "# 토크나이저 저장\n",
    "tokenizer.save_pretrained(save_directory)\n",
    "\n",
    "# 모델 저장\n",
    "kobert_model.save_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d052b6c6-27af-4aac-8a5f-80a8d3c9f942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d9fee1-cffd-45c5-85fb-0a96a14986a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368f5047-850f-452f-b973-a1ae75e6ae09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
