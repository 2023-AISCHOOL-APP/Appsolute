{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "947c3772-cbea-41d8-9212-f5e2ba340d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 17:10:21.004456: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-27 17:10:21.052513: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "554e785d-ad95-468a-92ac-a17ded342b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 데이터 로드\n",
    "data = pd.read_csv(\"./data/season.csv\")\n",
    "data=data.drop(\"Unnamed: 0\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aafe08da-16f2-4efa-b07e-ee78f6aabbfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "태그\n",
       "winter    3624\n",
       "fall      3600\n",
       "summer    3567\n",
       "spring    3483\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"태그\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "092bca16-9d4e-44f1-88cb-e740656fc104",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_680604/1052554418.py:18: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'Said you play a little hard to get And I bet it worked before but baby Honestly I dont like this back and forth I know you show me things to make me think its real But you never really tell me how you feel oh Hard to get With me with me What do you drink What do you smoke What do you do on Sundays alone Is it all on you or do you have someone to hold To tell you the truth You aint told me nothing at all Said you keeping your distance from me Then why do you text me cuz I aint ya bestie You know that its more than nothin Feel like ya test me but that doesnt make me down I see what youre doing But hear me when' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  data1.loc[i, \"가사\"] = first_part\n",
      "/tmp/ipykernel_680604/1052554418.py:19: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'spring' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  data1.loc[i, \"태그\"] = data[\"태그\"][i]\n",
      "/tmp/ipykernel_680604/1052554418.py:22: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'I tell ya now I already been through it So you dont have to feel me out oh I see what youre doing But hear me when I tell ya now I already been through it So you dont have to feel me out Said you play a little hard to get And I bet it worked before but baby Honestly I dont like this back and forth I know you show me things to make me think its real But you never really tell me how you feel oh Hard to get With me with me What do you drink What do you smoke What do you do on Sundays alone Do you go for a drive maybe down to the coast Dont you think it would be better if you did with somebody ya love Your' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  data2.loc[i, \"가사\"] = second_part\n",
      "/tmp/ipykernel_680604/1052554418.py:23: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'spring' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  data2.loc[i, \"태그\"] = data[\"태그\"][i]\n",
      "/tmp/ipykernel_680604/1052554418.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'distance from me Then why do you text me cuz I aint ya bestie You know that its more than nothin Feel like ya test me but that doesnt make me down I see what youre doing But hear me when I tell ya now I already been through it So you dont have to feel me out oh I see what youre doing But hear me when I tell ya now I already been through it So you dont have to feel me out Said you play a little hard to get And I bet it worked before but baby Honestly I dont like this back and forth I know you show me things to make me think its real But you never really tell me how you feel oh Hard to get With me with me' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  data3.loc[i, \"가사\"] = third_part\n",
      "/tmp/ipykernel_680604/1052554418.py:27: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'spring' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  data3.loc[i, \"태그\"] = data[\"태그\"][i]\n"
     ]
    }
   ],
   "source": [
    "# 새로운 데이터프레임 생성\n",
    "data1 = pd.DataFrame()\n",
    "data2 = pd.DataFrame()\n",
    "data3 = pd.DataFrame()\n",
    "\n",
    "# 원래 가사를 세 부분으로 나누어 세 데이터프레임에 추가\n",
    "for i in range(len(data[\"가사\"])):\n",
    "    list1 = list(str(data[\"가사\"][i]).split(\" \"))\n",
    "    length = len(list1)\n",
    "    one_third = length // 3\n",
    "    two_third = 2 * length // 3\n",
    "    \n",
    "    first_part = \" \".join(list1[:one_third])\n",
    "    second_part = \" \".join(list1[one_third:two_third])\n",
    "    third_part = \" \".join(list1[two_third:])\n",
    "    \n",
    "    # 첫 번째 데이터프레임에 추가\n",
    "    data1.loc[i, \"가사\"] = first_part\n",
    "    data1.loc[i, \"태그\"] = data[\"태그\"][i]\n",
    "    \n",
    "    # 두 번째 데이터프레임에 추가\n",
    "    data2.loc[i, \"가사\"] = second_part\n",
    "    data2.loc[i, \"태그\"] = data[\"태그\"][i]\n",
    "    \n",
    "    # 세 번째 데이터프레임에 추가\n",
    "    data3.loc[i, \"가사\"] = third_part\n",
    "    data3.loc[i, \"태그\"] = data[\"태그\"][i]\n",
    "\n",
    "# 세 데이터프레임 합치기\n",
    "data = pd.concat([data1, data2, data3], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04f7835c-ced5-4356-a07f-64c836c07dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(subset=['태그'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54b19fb2-aaa6-48bf-b133-b413cdb03ecb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # 가사길이를 앞부분만사용하기위해 100개의 단어까지만 받도록함\n",
    "# list1=[]\n",
    "# for i in range (len(data[\"가사\"])):\n",
    "#     list1=list(data[\"가사\"][i].split(\" \"))\n",
    "#     list1= list1[:100]\n",
    "#     data[\"가사\"][i]=\" \".join(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6107563c-0459-432a-8c15-15bc0291ff88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 17:11:25.109023: W tensorflow/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 350.24MiB (rounded to 367248384)requested by op StatelessTruncatedNormalV2\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-11-27 17:11:25.109067: I tensorflow/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2023-11-27 17:11:25.109076: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 7, Chunks in use: 7. 1.8KiB allocated for chunks. 1.8KiB in use in bin. 64B client-requested in use in bin.\n",
      "2023-11-27 17:11:25.109081: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-27 17:11:25.109086: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2023-11-27 17:11:25.109090: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-27 17:11:25.109094: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-27 17:11:25.109098: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-27 17:11:25.109102: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-27 17:11:25.109105: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-27 17:11:25.109109: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-27 17:11:25.109113: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-27 17:11:25.109117: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-27 17:11:25.109121: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-27 17:11:25.109124: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-27 17:11:25.109128: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-27 17:11:25.109131: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-27 17:11:25.109135: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-27 17:11:25.109139: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-27 17:11:25.109143: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-27 17:11:25.109147: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-27 17:11:25.109151: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 1, Chunks in use: 0. 171.89MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-27 17:11:25.109158: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 1, Chunks in use: 1. 350.24MiB allocated for chunks. 350.24MiB in use in bin. 350.24MiB client-requested in use in bin.\n",
      "2023-11-27 17:11:25.109163: I tensorflow/tsl/framework/bfc_allocator.cc:1062] Bin for 350.24MiB was 256.00MiB, Chunk State: \n",
      "2023-11-27 17:11:25.109168: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 547487744\n",
      "2023-11-27 17:11:25.109176: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f89e6000000 of size 256 next 1\n",
      "2023-11-27 17:11:25.109180: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f89e6000100 of size 1280 next 2\n",
      "2023-11-27 17:11:25.109183: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f89e6000600 of size 256 next 3\n",
      "2023-11-27 17:11:25.109186: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f89e6000700 of size 256 next 4\n",
      "2023-11-27 17:11:25.109189: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f89e6000800 of size 256 next 5\n",
      "2023-11-27 17:11:25.109192: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f89e6000900 of size 256 next 6\n",
      "2023-11-27 17:11:25.109195: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f89e6000a00 of size 367248384 next 7\n",
      "2023-11-27 17:11:25.109200: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f89fbe3ce00 of size 256 next 8\n",
      "2023-11-27 17:11:25.109203: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f89fbe3cf00 of size 256 next 9\n",
      "2023-11-27 17:11:25.109206: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f89fbe3d000 of size 180236288 next 18446744073709551615\n",
      "2023-11-27 17:11:25.109209: I tensorflow/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2023-11-27 17:11:25.109214: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 7 Chunks of size 256 totalling 1.8KiB\n",
      "2023-11-27 17:11:25.109218: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-11-27 17:11:25.109221: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 367248384 totalling 350.24MiB\n",
      "2023-11-27 17:11:25.109225: I tensorflow/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 350.24MiB\n",
      "2023-11-27 17:11:25.109229: I tensorflow/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 547487744 memory_limit_: 547487744 available bytes: 0 curr_region_allocation_bytes_: 1094975488\n",
      "2023-11-27 17:11:25.109236: I tensorflow/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                       547487744\n",
      "InUse:                       367251456\n",
      "MaxInUse:                    367251456\n",
      "NumAllocs:                          13\n",
      "MaxAllocSize:                367248384\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-11-27 17:11:25.109241: W tensorflow/tsl/framework/bfc_allocator.cc:497] ********************************************************************________________________________\n",
      "2023-11-27 17:11:25.109262: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at stateless_random_ops_v2.cc:64 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[119547,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Exception encountered when calling layer 'bert' (type TFBertMainLayer).\n\n{{function_node __wrapped__StatelessTruncatedNormalV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[119547,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:StatelessTruncatedNormalV2]\n\nCall arguments received by layer 'bert' (type TFBertMainLayer):\n  • input_ids=tf.Tensor(shape=(1, 2), dtype=int32)\n  • attention_mask=tf.Tensor(shape=(1, 2), dtype=int32)\n  • token_type_ids=tf.Tensor(shape=(1, 2), dtype=int32)\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=True\n  • output_attentions=False\n  • output_hidden_states=False\n  • return_dict=True\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# BERT 모델 및 토크나이저 로드\u001b[39;00m\n\u001b[1;32m      2\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m BertTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-multilingual-cased\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m bert_model \u001b[38;5;241m=\u001b[39m \u001b[43mTFBertModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbert-base-multilingual-cased\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf212_py310/lib/python3.10/site-packages/transformers/modeling_tf_utils.py:2912\u001b[0m, in \u001b[0;36mTFPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2910\u001b[0m         model\u001b[38;5;241m.\u001b[39mbuild()  \u001b[38;5;66;03m# build the network with dummy inputs\u001b[39;00m\n\u001b[1;32m   2911\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2912\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# build the network with dummy inputs\u001b[39;00m\n\u001b[1;32m   2914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m safetensors_from_pt:\n\u001b[1;32m   2915\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_tf_pytorch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_pytorch_state_dict_in_tf2_model\n",
      "File \u001b[0;32m~/miniforge3/envs/tf212_py310/lib/python3.10/site-packages/transformers/modeling_tf_utils.py:1140\u001b[0m, in \u001b[0;36mTFPreTrainedModel.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;66;03m# Set the serving spec quickly to ensure that Keras doesn't use the specific dummy input shapes as the spec\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;66;03m# Setting it in build() allows users to override the shape when loading a non-pretrained model from config\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_save_spec(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_signature)\n\u001b[0;32m-> 1140\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdummy_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf212_py310/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniforge3/envs/tf212_py310/lib/python3.10/site-packages/transformers/modeling_tf_utils.py:426\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m    425\u001b[0m unpacked_inputs \u001b[38;5;241m=\u001b[39m input_processing(func, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_args_and_kwargs)\n\u001b[0;32m--> 426\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43munpacked_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf212_py310/lib/python3.10/site-packages/transformers/models/bert/modeling_tf_bert.py:1088\u001b[0m, in \u001b[0;36mTFBertModel.call\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;129m@unpack_inputs\u001b[39m\n\u001b[1;32m   1045\u001b[0m \u001b[38;5;129m@add_start_docstrings_to_model_forward\u001b[39m(BERT_INPUTS_DOCSTRING\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size, sequence_length\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1046\u001b[0m \u001b[38;5;129m@add_code_sample_docstrings\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1066\u001b[0m     training: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1067\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[TFBaseModelOutputWithPoolingAndCrossAttentions, Tuple[tf\u001b[38;5;241m.\u001b[39mTensor]]:\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;124;03m    encoder_hidden_states  (`tf.Tensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;124;03m        Sequence of hidden-states at the output of the last layer of the encoder. Used in the cross-attention if\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;124;03m        `past_key_values`). Set to `False` during training, `True` during generation\u001b[39;00m\n\u001b[1;32m   1087\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/miniforge3/envs/tf212_py310/lib/python3.10/site-packages/transformers/modeling_tf_utils.py:426\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m    425\u001b[0m unpacked_inputs \u001b[38;5;241m=\u001b[39m input_processing(func, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_args_and_kwargs)\n\u001b[0;32m--> 426\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43munpacked_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf212_py310/lib/python3.10/site-packages/transformers/models/bert/modeling_tf_bert.py:780\u001b[0m, in \u001b[0;36mTFBertMainLayer.call\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token_type_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    778\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfill(dims\u001b[38;5;241m=\u001b[39minput_shape, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 780\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;66;03m# We create a 3D attention mask from a 2D tensor mask.\u001b[39;00m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;66;03m# Sizes are [batch_size, 1, 1, to_seq_length]\u001b[39;00m\n\u001b[1;32m    791\u001b[0m \u001b[38;5;66;03m# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]\u001b[39;00m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;66;03m# this attention mask is more simple than the triangular masking of causal attention\u001b[39;00m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;66;03m# used in OpenAI GPT, we just need to prepare the broadcast dimension here.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m attention_mask_shape \u001b[38;5;241m=\u001b[39m shape_list(attention_mask)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf212_py310/lib/python3.10/site-packages/transformers/models/bert/modeling_tf_bert.py:161\u001b[0m, in \u001b[0;36mTFBertEmbeddings.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_shape: tf\u001b[38;5;241m.\u001b[39mTensorShape):\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mword_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 161\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_weight\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m            \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m            \u001b[49m\u001b[43minitializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_initializer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitializer_range\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_type_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_weight(\n\u001b[1;32m    169\u001b[0m             name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    170\u001b[0m             shape\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtype_vocab_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size],\n\u001b[1;32m    171\u001b[0m             initializer\u001b[38;5;241m=\u001b[39mget_initializer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitializer_range),\n\u001b[1;32m    172\u001b[0m         )\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Exception encountered when calling layer 'bert' (type TFBertMainLayer).\n\n{{function_node __wrapped__StatelessTruncatedNormalV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[119547,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:StatelessTruncatedNormalV2]\n\nCall arguments received by layer 'bert' (type TFBertMainLayer):\n  • input_ids=tf.Tensor(shape=(1, 2), dtype=int32)\n  • attention_mask=tf.Tensor(shape=(1, 2), dtype=int32)\n  • token_type_ids=tf.Tensor(shape=(1, 2), dtype=int32)\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=True\n  • output_attentions=False\n  • output_hidden_states=False\n  • return_dict=True\n  • training=False"
     ]
    }
   ],
   "source": [
    "# BERT 모델 및 토크나이저 로드\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-multilingual-cased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e62b15c4-5f03-4b9e-944c-df3f12cce3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감정 태그를 숫자로 매핑\n",
    "tag_mapping = {tag: idx for idx, tag in enumerate(data['태그'].unique())}\n",
    "inverse_tag_mapping = {v: k for k, v in tag_mapping.items()}\n",
    "data['태그_encoded'] = data['태그'].map(tag_mapping)\n",
    "\n",
    "# 데이터 분할\n",
    "train,test= train_test_split(data[[\"가사\",'태그_encoded']], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65996047-cbb3-4a9b-891f-a66621acd2bc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>가사</th>\n",
       "      <th>태그_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>We're a long way from home Haven't seen you in...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3016</th>\n",
       "      <td>Does she move like air? Yeah I bet they stop a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>알기에 우리의 밤이 끝나지 않기만 바래요 눈 속에 핀 꽃처럼 우린 봄을 함께 하진 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3172</th>\n",
       "      <td>say Can't we just leave and walk away? Walk aw...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4734</th>\n",
       "      <td>I miss the</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>날 비가 내리는 날에는 나를 생각해줘요 함께 걸었던 거리를 기억해줘요 비가 내리는 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>의미 Date, Just 떳떳하게 너의 앞에 선 나를 상상해온 길었던 시간을 달려서...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>like I’m paralyzed) cause I’ve been staying up...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>How can i forget you girl damage from your smi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2510</th>\n",
       "      <td>those beautiful days when there was no money W...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7616 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     가사  태그_encoded\n",
       "2484  We're a long way from home Haven't seen you in...           2\n",
       "3016  Does she move like air? Yeah I bet they stop a...           2\n",
       "532   알기에 우리의 밤이 끝나지 않기만 바래요 눈 속에 핀 꽃처럼 우린 봄을 함께 하진 ...           0\n",
       "3172  say Can't we just leave and walk away? Walk aw...           2\n",
       "4734                                         I miss the           3\n",
       "...                                                 ...         ...\n",
       "974   날 비가 내리는 날에는 나를 생각해줘요 함께 걸었던 거리를 기억해줘요 비가 내리는 ...           0\n",
       "431   의미 Date, Just 떳떳하게 너의 앞에 선 나를 상상해온 길었던 시간을 달려서...           0\n",
       "630   like I’m paralyzed) cause I’ve been staying up...           0\n",
       "860   How can i forget you girl damage from your smi...           0\n",
       "2510  those beautiful days when there was no money W...           2\n",
       "\n",
       "[7616 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed33b04b-7723-414d-a3a9-f39850509cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spring', 'summer', 'fall', 'winter'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"태그\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9640de5e-6db5-4f8f-85bc-e3c467745e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tokenizer(\n",
    "    text=train.가사.tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=100,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)\n",
    "\n",
    "\n",
    "x_test = tokenizer(\n",
    "    text=test.가사.tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=100,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03b35c1d-8966-47e8-bb21-1fb712d94f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100,), dtype=int32, numpy=\n",
       "array([   101,   9257,  77884,   9087,  48387,  18108,   9290,   9937,\n",
       "       118632,  10622,    100,   8924, 118729,   9004,  11287,   9682,\n",
       "         9524,  26737, 119221, 103014,   9670, 118775,  10622,   9524,\n",
       "        14153,   9097,  10622,    100,   9995,  11102,   9309,  86488,\n",
       "         8996,  14153,   9695,   8982,  11513,   9670,  25387,   9290,\n",
       "         9730,  12692,  14153,   9248,  93200, 119221,   8984,   9590,\n",
       "        31401,  31401,   9294,  70162,  68833,   9251,  16985,   8982,\n",
       "        10459,   9253,  10892,   9590,  31401,  31401,   8996,  14153,\n",
       "         9638,  30873,  12508,   9246,  17073,   9004,  40364,   9952,\n",
       "        35866,  11018,   9414,  14871,  22440,  20626,  23466,   9490,\n",
       "        10892,   8867,   9519,  32537, 118627,  12092,   9955,   9460,\n",
       "         9555,  10622,   8867,   8984,   9318,  30005,  11287,   9096,\n",
       "        41605,  85836,   8863,    102], dtype=int32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[\"input_ids\"][200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5ddeb4c-55e4-4e5e-b37b-40dfd01164c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a9729a3-9833-4167-adb6-5c15968261f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 100\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "input_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
    "input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n",
    "embeddings = bert_model(input_ids,attention_mask = input_mask)[0] #(0 is the last hidden states,1 means pooler_output)\n",
    "out = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
    "out = tf.keras.layers.Dropout(0.3)(out)\n",
    "out = Dense(1024, activation='relu')(out)\n",
    "out = tf.keras.layers.Dropout(0.3)(out)\n",
    "out = Dense(256, activation='relu')(out)\n",
    "out = tf.keras.layers.Dropout(0.3)(out)\n",
    "out = Dense(32,activation = 'relu')(out)\n",
    "\n",
    "y = Dense(4,activation = 'softmax')(out)\n",
    "    \n",
    "model = tf.keras.Model(inputs=[input_ids, input_mask], outputs=y)\n",
    "model.layers[2].trainable = True\n",
    "# for training bert our lr must be so small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48c249c1-5879-4c2f-9db6-cfca40c95fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.legacy.Adam(\n",
    "    learning_rate=5e-05, # this learning rate is for bert model , taken from huggingface website \n",
    "    \n",
    "    clipnorm=1.0)\n",
    "\n",
    "# Set loss and metrics\n",
    "loss =CategoricalCrossentropy(from_logits = True)\n",
    "metric = CategoricalAccuracy(),\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = loss, \n",
    "    metrics = metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8e66801-16fe-4e2e-bc2f-a5874f7e0472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  177853440   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 100,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " global_max_pooling1d_1 (Global  (None, 768)         0           ['tf_bert_model[1][0]']          \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_39 (Dropout)           (None, 768)          0           ['global_max_pooling1d_1[0][0]'] \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 1024)         787456      ['dropout_39[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_40 (Dropout)           (None, 1024)         0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 256)          262400      ['dropout_40[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_41 (Dropout)           (None, 256)          0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 32)           8224        ['dropout_41[0][0]']             \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 4)            132         ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 178,911,652\n",
      "Trainable params: 178,911,652\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc83488a-09a3-4fcb-9113-68a8f6c0b086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniforge3/envs/tf212_py310/lib/python3.10/site-packages/keras/backend.py:5561: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "179/179 [==============================] - 34s 113ms/step - loss: 0.9941 - categorical_accuracy: 0.5843 - val_loss: 1.2104 - val_categorical_accuracy: 0.4806\n",
      "Epoch 2/50\n",
      "179/179 [==============================] - 18s 98ms/step - loss: 0.8436 - categorical_accuracy: 0.6637 - val_loss: 1.2927 - val_categorical_accuracy: 0.4757\n",
      "Epoch 3/50\n",
      "179/179 [==============================] - 19s 105ms/step - loss: 0.7408 - categorical_accuracy: 0.7096 - val_loss: 1.3012 - val_categorical_accuracy: 0.4883\n",
      "Epoch 4/50\n",
      "179/179 [==============================] - 17s 98ms/step - loss: 0.6544 - categorical_accuracy: 0.7505 - val_loss: 1.4754 - val_categorical_accuracy: 0.4963\n",
      "Epoch 5/50\n",
      "179/179 [==============================] - 17s 98ms/step - loss: 0.5828 - categorical_accuracy: 0.7809 - val_loss: 1.4188 - val_categorical_accuracy: 0.5096\n",
      "Epoch 6/50\n",
      "179/179 [==============================] - 19s 105ms/step - loss: 0.5279 - categorical_accuracy: 0.8021 - val_loss: 1.5708 - val_categorical_accuracy: 0.5142\n"
     ]
    }
   ],
   "source": [
    "# 가사 앞뒤로 나눠서 2배로 늘린 모델\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# EarlyStopping 콜백 정의\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# 모델 학습에 EarlyStopping 콜백 적용\n",
    "train_history = model.fit(\n",
    "    x={'input_ids': x_train['input_ids'], 'attention_mask': x_train['attention_mask']},\n",
    "    y=to_categorical(train.태그_encoded),\n",
    "    validation_data=(\n",
    "        {'input_ids': x_test['input_ids'], 'attention_mask': x_test['attention_mask']},\n",
    "        to_categorical(test.태그_encoded)),\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2c5f20-30ee-4d97-8903-f21ae0c7abcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_history = model.fit(\n",
    "    x ={'input_ids':x_train['input_ids'],'attention_mask':x_train['attention_mask']} ,\n",
    "    y = to_categorical(train.태그_encoded),\n",
    "    validation_data = (\n",
    "    {'input_ids':x_test['input_ids'],'attention_mask':x_test['attention_mask']}, to_categorical(test.태그_encoded)),\n",
    "    epochs=50,\n",
    "    batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2982d2fe-ce63-44cb-9a41-b4cc825440a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 4s 22ms/step\n",
      "Predicted Tags: ['spring', 'fall', 'spring', 'summer', 'spring', 'summer', 'fall', 'summer', 'summer', 'fall', 'winter', 'summer', 'fall', 'summer', 'spring', 'spring', 'fall', 'fall', 'summer', 'winter', 'spring', 'fall', 'spring', 'fall', 'spring', 'summer', 'summer', 'fall', 'spring', 'summer', 'fall', 'spring', 'spring', 'spring', 'winter', 'summer', 'summer', 'fall', 'spring', 'spring', 'winter', 'fall', 'spring', 'spring', 'summer', 'winter', 'fall', 'fall', 'winter', 'spring', 'fall', 'spring', 'fall', 'fall', 'fall', 'fall', 'fall', 'summer', 'summer', 'summer', 'spring', 'summer', 'summer', 'fall', 'fall', 'summer', 'winter', 'summer', 'spring', 'spring', 'winter', 'summer', 'fall', 'spring', 'winter', 'winter', 'summer', 'fall', 'summer', 'spring', 'spring', 'spring', 'spring', 'summer', 'winter', 'summer', 'fall', 'winter', 'winter', 'summer', 'summer', 'summer', 'summer', 'fall', 'spring', 'fall', 'spring', 'fall', 'spring', 'winter', 'fall', 'fall', 'fall', 'fall', 'winter', 'fall', 'spring', 'fall', 'spring', 'spring', 'winter', 'spring', 'fall', 'fall', 'fall', 'fall', 'winter', 'spring', 'spring', 'spring', 'winter', 'winter', 'fall', 'fall', 'fall', 'winter', 'fall', 'spring', 'fall', 'winter', 'summer', 'spring', 'spring', 'spring', 'fall', 'winter', 'fall', 'spring', 'summer', 'fall', 'fall', 'summer', 'fall', 'fall', 'fall', 'spring', 'fall', 'spring', 'spring', 'spring', 'spring', 'summer', 'spring', 'winter', 'summer', 'fall', 'spring', 'spring', 'fall', 'winter', 'summer', 'winter', 'summer', 'fall', 'summer', 'winter', 'fall', 'summer', 'fall', 'fall', 'spring', 'fall', 'fall', 'spring', 'spring', 'winter', 'spring', 'spring', 'fall', 'spring', 'winter', 'fall', 'fall', 'spring', 'fall', 'fall', 'fall', 'winter', 'spring', 'fall', 'fall', 'fall', 'fall', 'winter', 'summer', 'fall', 'spring', 'winter', 'fall', 'fall', 'spring', 'fall', 'summer', 'fall', 'fall', 'spring', 'fall', 'winter', 'winter', 'fall', 'fall', 'fall', 'spring', 'spring', 'winter', 'fall', 'summer', 'winter', 'summer', 'spring', 'fall', 'fall', 'spring', 'spring', 'winter', 'fall', 'summer', 'summer', 'spring', 'winter', 'spring', 'spring', 'fall', 'spring', 'spring', 'fall', 'spring', 'winter', 'fall', 'fall', 'fall', 'summer', 'fall', 'fall', 'summer', 'fall', 'summer', 'fall', 'spring', 'fall', 'fall', 'fall', 'spring', 'fall', 'summer', 'winter', 'spring', 'spring', 'fall', 'spring', 'spring', 'spring', 'winter', 'fall', 'winter', 'winter', 'winter', 'winter', 'spring', 'summer', 'fall', 'spring', 'summer', 'fall', 'winter', 'summer', 'summer', 'spring', 'fall', 'winter', 'spring', 'winter', 'fall', 'fall', 'winter', 'fall', 'winter', 'spring', 'fall', 'summer', 'summer', 'fall', 'fall', 'winter', 'summer', 'fall', 'fall', 'summer', 'summer', 'fall', 'summer', 'fall', 'spring', 'winter', 'winter', 'spring', 'fall', 'fall', 'summer', 'fall', 'summer', 'fall', 'spring', 'spring', 'fall', 'fall', 'spring', 'spring', 'fall', 'fall', 'fall', 'summer', 'spring', 'spring', 'winter', 'fall', 'winter', 'fall', 'fall', 'winter', 'summer', 'fall', 'fall', 'fall', 'spring', 'spring', 'fall', 'summer', 'fall', 'spring', 'winter', 'spring', 'fall', 'spring', 'fall', 'summer', 'fall', 'spring', 'fall', 'summer', 'winter', 'spring', 'summer', 'fall', 'summer', 'spring', 'summer', 'winter', 'spring', 'spring', 'spring', 'fall', 'summer', 'fall', 'spring', 'summer', 'fall', 'fall', 'spring', 'fall', 'spring', 'spring', 'spring', 'winter', 'fall', 'summer', 'spring', 'spring', 'fall', 'spring', 'fall', 'summer', 'summer', 'fall', 'fall', 'spring', 'summer', 'fall', 'summer', 'spring', 'spring', 'spring', 'spring', 'fall', 'spring', 'summer', 'winter', 'fall', 'summer', 'spring', 'fall', 'summer', 'fall', 'fall', 'summer', 'fall', 'spring', 'fall', 'winter', 'winter', 'fall', 'fall', 'winter', 'summer', 'spring', 'fall', 'fall', 'fall', 'summer', 'fall', 'fall', 'spring', 'winter', 'spring', 'spring', 'spring', 'summer', 'fall', 'spring', 'fall', 'spring', 'fall', 'winter', 'fall', 'spring', 'summer', 'winter', 'spring', 'spring', 'spring', 'fall', 'spring', 'spring', 'fall', 'summer', 'fall', 'fall', 'fall', 'summer', 'spring', 'fall', 'fall', 'fall', 'summer', 'fall', 'spring', 'winter', 'fall', 'fall', 'fall', 'spring', 'fall', 'winter', 'fall', 'winter', 'winter', 'fall', 'fall', 'winter', 'winter', 'spring', 'summer', 'summer', 'winter', 'spring', 'summer', 'fall', 'fall', 'summer', 'spring', 'fall', 'fall', 'spring', 'spring', 'spring', 'spring', 'winter', 'summer', 'spring', 'spring', 'spring', 'spring', 'winter', 'winter', 'spring', 'summer', 'spring', 'fall', 'summer', 'summer', 'summer', 'spring', 'fall', 'summer', 'summer', 'spring', 'spring', 'winter', 'spring', 'fall', 'winter', 'spring', 'fall', 'spring', 'spring', 'fall', 'fall', 'summer', 'summer', 'fall', 'spring', 'summer', 'fall', 'fall', 'fall', 'fall', 'spring', 'summer', 'fall', 'fall', 'spring', 'winter', 'spring', 'winter', 'spring', 'fall', 'winter', 'winter', 'winter', 'spring', 'winter', 'summer', 'fall', 'spring', 'summer', 'winter', 'winter', 'fall', 'fall', 'summer', 'fall', 'fall', 'winter', 'summer', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'spring', 'summer', 'fall', 'winter', 'fall', 'winter', 'spring', 'fall', 'winter', 'fall', 'spring', 'spring', 'fall', 'spring', 'summer', 'spring', 'winter', 'fall', 'fall', 'spring', 'fall', 'fall', 'winter', 'winter', 'summer', 'fall', 'fall', 'spring', 'fall', 'summer', 'spring', 'spring', 'summer', 'spring', 'fall', 'fall', 'summer', 'spring', 'spring', 'summer', 'fall', 'fall', 'winter', 'fall', 'fall', 'fall', 'summer', 'fall', 'spring', 'spring', 'fall', 'summer', 'fall', 'fall', 'fall', 'winter', 'winter', 'summer', 'winter', 'winter', 'summer', 'fall', 'summer', 'fall', 'fall', 'winter', 'winter', 'fall', 'fall', 'spring', 'fall', 'winter', 'fall', 'fall', 'summer', 'fall', 'summer', 'fall', 'winter', 'fall', 'winter', 'spring', 'summer', 'fall', 'fall', 'spring', 'winter', 'fall', 'summer', 'spring', 'summer', 'winter', 'fall', 'spring', 'fall', 'fall', 'fall', 'winter', 'spring', 'fall', 'winter', 'winter', 'spring', 'spring', 'summer', 'summer', 'fall', 'winter', 'fall', 'fall', 'spring', 'summer', 'fall', 'summer', 'fall', 'fall', 'winter', 'fall', 'fall', 'fall', 'spring', 'fall', 'spring', 'fall', 'spring', 'spring', 'fall', 'fall', 'fall', 'winter', 'summer', 'summer', 'spring', 'summer', 'spring', 'winter', 'spring', 'spring', 'fall', 'fall', 'winter', 'winter', 'spring', 'fall', 'fall', 'fall', 'fall', 'winter', 'summer', 'fall', 'spring', 'winter', 'spring', 'summer', 'spring', 'fall', 'spring', 'winter', 'spring', 'winter', 'fall', 'fall', 'fall', 'summer', 'fall', 'winter', 'spring', 'spring', 'spring', 'winter', 'fall', 'spring', 'spring', 'fall', 'fall', 'summer', 'summer', 'spring', 'fall', 'fall', 'fall', 'fall', 'summer', 'fall', 'summer', 'spring', 'fall', 'winter', 'fall', 'winter', 'fall', 'fall', 'summer', 'winter', 'fall', 'fall', 'summer', 'spring', 'fall', 'spring', 'spring', 'fall', 'fall', 'fall', 'fall', 'spring', 'spring', 'summer', 'fall', 'winter', 'winter', 'fall', 'fall', 'fall', 'spring', 'fall', 'winter', 'spring', 'spring', 'spring', 'fall', 'summer', 'fall', 'spring', 'summer', 'winter', 'fall', 'winter', 'summer', 'spring', 'summer', 'summer', 'fall', 'fall', 'fall', 'fall', 'fall', 'spring', 'summer', 'winter', 'fall', 'spring', 'fall', 'winter', 'fall', 'fall', 'fall', 'fall', 'winter', 'spring', 'summer', 'winter', 'fall', 'winter', 'fall', 'winter', 'winter', 'spring', 'fall', 'fall', 'spring', 'fall', 'fall', 'spring', 'summer', 'summer', 'fall', 'spring', 'fall', 'fall', 'fall', 'spring', 'summer', 'fall', 'winter', 'fall', 'summer', 'spring', 'fall', 'spring', 'spring', 'spring', 'fall', 'fall', 'fall', 'summer', 'spring', 'winter', 'winter', 'spring', 'fall', 'spring', 'fall', 'spring', 'spring', 'fall', 'spring', 'summer', 'summer', 'fall', 'summer', 'winter', 'summer', 'summer', 'fall', 'fall', 'winter', 'summer', 'spring', 'summer', 'fall', 'winter', 'spring', 'summer', 'spring', 'spring', 'fall', 'winter', 'spring', 'spring', 'spring', 'summer', 'spring', 'spring', 'winter', 'fall', 'fall', 'fall', 'fall', 'spring', 'spring', 'winter', 'summer', 'spring', 'spring', 'spring', 'spring', 'fall', 'spring', 'spring', 'spring', 'summer', 'summer', 'fall', 'fall', 'fall', 'fall', 'fall', 'spring', 'fall', 'summer', 'fall', 'fall', 'winter', 'spring', 'spring', 'fall', 'spring', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'winter', 'fall', 'summer', 'summer', 'summer', 'spring', 'spring', 'winter', 'summer', 'summer', 'fall', 'fall', 'spring', 'spring', 'spring', 'fall', 'spring', 'spring', 'fall', 'spring', 'fall', 'spring', 'winter', 'spring', 'summer', 'spring', 'fall', 'summer', 'summer', 'fall', 'fall', 'fall', 'fall', 'spring', 'fall', 'fall', 'summer', 'winter', 'spring', 'spring', 'fall', 'fall', 'fall', 'fall', 'fall', 'winter', 'summer', 'spring', 'summer', 'winter', 'fall', 'spring', 'winter', 'summer', 'fall', 'spring', 'fall', 'spring', 'winter', 'fall', 'summer', 'fall', 'winter', 'spring', 'fall', 'fall', 'fall', 'spring', 'fall', 'fall', 'summer', 'spring', 'summer', 'fall', 'fall', 'fall', 'summer', 'winter', 'fall', 'winter', 'summer', 'summer', 'fall', 'spring', 'fall', 'spring', 'summer', 'fall', 'winter', 'fall', 'fall', 'summer', 'fall', 'spring', 'spring', 'fall', 'fall', 'spring', 'fall', 'fall', 'fall', 'fall', 'fall', 'winter', 'fall', 'winter', 'spring', 'fall', 'fall', 'spring', 'spring', 'summer', 'winter', 'fall', 'spring', 'fall', 'spring', 'summer', 'spring', 'summer', 'fall', 'fall', 'summer', 'fall', 'summer', 'winter', 'fall', 'summer', 'fall', 'winter', 'summer', 'spring', 'fall', 'winter', 'spring', 'summer', 'fall', 'spring', 'summer', 'spring', 'fall', 'fall', 'spring', 'fall', 'winter', 'winter', 'fall', 'summer', 'fall', 'fall', 'summer', 'summer', 'spring', 'spring', 'fall', 'spring', 'spring', 'spring', 'fall', 'spring', 'fall', 'fall', 'fall', 'spring', 'fall', 'summer', 'summer', 'fall', 'summer', 'summer', 'summer', 'fall', 'fall', 'fall', 'fall', 'spring', 'fall', 'spring', 'summer', 'summer', 'fall', 'fall', 'fall', 'fall', 'fall', 'spring', 'summer', 'fall', 'fall', 'fall', 'fall', 'fall', 'spring', 'summer', 'spring', 'spring', 'summer', 'fall', 'fall', 'fall', 'winter', 'fall', 'fall', 'spring', 'summer', 'summer', 'fall', 'winter', 'fall', 'fall', 'spring', 'fall', 'spring', 'summer', 'spring', 'winter', 'fall', 'fall', 'winter', 'winter', 'summer', 'summer', 'fall', 'summer', 'fall', 'winter', 'fall', 'fall', 'fall', 'spring', 'fall', 'fall', 'summer', 'fall', 'winter', 'winter', 'winter', 'fall', 'summer', 'winter', 'fall', 'fall', 'fall', 'spring', 'summer', 'fall', 'fall', 'spring', 'fall', 'summer', 'spring', 'spring', 'winter', 'winter', 'fall', 'spring', 'fall', 'fall', 'fall', 'spring', 'spring', 'winter', 'spring', 'fall', 'fall', 'fall', 'spring', 'summer', 'summer', 'fall', 'fall', 'winter', 'winter', 'fall', 'fall', 'winter', 'summer', 'summer', 'fall', 'fall', 'summer', 'winter', 'fall', 'spring', 'fall', 'spring', 'fall', 'fall', 'fall', 'winter', 'summer', 'spring', 'spring', 'spring', 'summer', 'summer', 'spring', 'winter', 'summer', 'spring', 'fall', 'summer', 'fall', 'spring', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'spring', 'fall', 'fall', 'winter', 'winter', 'summer', 'winter', 'fall', 'spring', 'spring', 'fall', 'fall', 'winter', 'fall', 'summer', 'fall', 'spring', 'fall', 'fall', 'fall', 'winter', 'fall', 'summer', 'fall', 'spring', 'fall', 'fall', 'spring', 'fall', 'summer', 'fall', 'summer', 'fall', 'fall', 'fall', 'spring', 'winter', 'spring', 'fall', 'spring', 'spring', 'fall', 'spring', 'fall', 'winter', 'fall', 'fall', 'summer', 'fall', 'fall', 'summer', 'spring', 'fall', 'fall', 'summer', 'summer', 'spring', 'winter', 'summer', 'fall', 'spring', 'fall', 'summer', 'winter', 'summer', 'winter', 'summer', 'summer', 'spring', 'winter', 'fall', 'spring', 'spring', 'summer', 'fall', 'fall', 'summer', 'fall', 'spring', 'fall', 'fall', 'fall', 'fall', 'spring', 'fall', 'summer', 'fall', 'summer', 'winter', 'spring', 'summer', 'winter', 'fall', 'summer', 'fall', 'summer', 'winter', 'spring', 'fall', 'winter', 'fall', 'spring', 'spring', 'fall', 'fall', 'fall', 'spring', 'spring', 'spring', 'fall', 'fall', 'fall', 'fall', 'winter', 'fall', 'summer', 'fall', 'spring', 'fall', 'spring', 'spring', 'fall', 'summer', 'summer', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'winter', 'spring', 'spring', 'fall', 'fall', 'spring', 'winter', 'summer', 'winter', 'fall', 'fall', 'summer', 'spring', 'summer', 'winter', 'winter', 'winter', 'winter', 'summer', 'winter', 'fall', 'fall', 'summer', 'summer', 'winter', 'spring', 'winter', 'winter', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'summer', 'summer', 'winter', 'fall', 'summer', 'fall', 'winter', 'summer', 'fall', 'spring', 'fall', 'fall', 'fall', 'winter', 'fall', 'spring', 'winter', 'summer', 'fall', 'summer', 'fall', 'spring', 'winter', 'fall', 'fall', 'winter', 'spring', 'fall', 'winter', 'winter', 'fall', 'summer', 'spring', 'fall', 'fall', 'fall', 'winter', 'summer', 'winter', 'fall', 'spring', 'winter', 'summer', 'summer', 'fall', 'fall', 'spring', 'spring', 'summer', 'fall', 'fall', 'spring', 'fall', 'spring', 'fall', 'fall', 'summer', 'winter', 'fall', 'fall', 'winter', 'summer', 'fall', 'winter', 'spring', 'spring', 'fall', 'fall', 'spring', 'fall', 'summer', 'fall', 'winter', 'summer', 'spring', 'summer', 'summer', 'summer', 'fall', 'spring', 'fall', 'fall', 'winter', 'fall', 'fall', 'spring', 'fall', 'winter', 'spring', 'spring', 'winter', 'spring', 'winter', 'fall', 'fall', 'spring', 'winter', 'fall', 'spring', 'spring', 'winter', 'fall', 'spring', 'spring', 'fall', 'spring', 'summer', 'winter', 'spring', 'winter', 'winter', 'fall', 'fall', 'winter', 'fall', 'fall', 'spring', 'spring', 'fall', 'fall', 'winter', 'spring', 'fall', 'spring', 'fall', 'winter', 'summer', 'spring', 'spring', 'fall', 'fall', 'fall', 'fall', 'winter', 'fall', 'winter', 'spring', 'fall', 'spring', 'summer', 'summer', 'winter', 'winter', 'winter', 'spring', 'spring', 'fall', 'summer', 'summer', 'spring', 'summer', 'fall', 'fall', 'spring', 'summer', 'spring', 'fall', 'fall', 'fall', 'summer', 'summer', 'spring', 'fall', 'summer', 'spring', 'fall', 'winter', 'summer', 'fall', 'summer', 'summer', 'winter', 'fall', 'summer', 'summer', 'fall', 'spring', 'fall', 'fall', 'spring', 'summer', 'fall', 'winter', 'fall', 'spring', 'fall', 'fall', 'fall', 'fall', 'summer', 'spring', 'fall', 'fall', 'summer', 'summer', 'fall', 'fall', 'winter', 'fall', 'summer', 'spring', 'fall', 'fall', 'fall', 'summer', 'fall', 'spring', 'fall', 'summer', 'fall', 'fall', 'fall', 'fall', 'summer', 'fall', 'fall', 'winter', 'summer', 'winter', 'fall', 'summer', 'summer', 'fall', 'winter', 'summer', 'spring', 'fall', 'fall', 'fall', 'fall', 'spring', 'winter', 'fall', 'fall', 'spring', 'fall', 'fall', 'summer', 'spring', 'spring', 'spring', 'fall', 'fall', 'fall', 'spring', 'fall', 'summer', 'fall', 'winter', 'fall', 'spring', 'fall', 'spring', 'fall', 'spring', 'summer', 'spring', 'fall', 'fall', 'spring', 'fall', 'fall', 'fall', 'spring', 'summer', 'summer', 'winter', 'spring', 'summer', 'spring', 'fall', 'winter', 'fall', 'spring', 'fall', 'spring', 'fall', 'summer', 'fall', 'spring', 'spring', 'winter', 'spring', 'fall', 'fall', 'fall', 'spring', 'summer', 'summer', 'fall', 'fall', 'fall', 'summer', 'fall', 'spring', 'spring', 'winter', 'summer', 'spring', 'spring', 'fall', 'spring', 'winter', 'summer', 'fall', 'summer', 'winter', 'fall', 'spring', 'fall', 'fall', 'fall', 'fall', 'summer', 'winter', 'summer', 'fall', 'winter', 'fall', 'spring', 'spring', 'spring', 'winter', 'summer', 'winter', 'fall', 'winter', 'summer', 'fall', 'summer', 'fall', 'fall', 'fall', 'fall', 'fall', 'spring', 'fall', 'summer', 'fall', 'fall', 'fall', 'fall', 'fall', 'summer', 'summer', 'fall', 'fall', 'summer', 'summer', 'spring', 'fall', 'summer', 'fall', 'summer', 'fall', 'fall', 'summer', 'winter', 'summer', 'fall', 'summer', 'winter', 'fall', 'fall', 'spring', 'winter', 'summer', 'fall', 'winter', 'fall', 'fall', 'spring', 'summer', 'winter', 'summer', 'summer', 'spring', 'spring', 'summer', 'fall', 'fall', 'fall', 'summer', 'spring', 'winter', 'spring', 'summer', 'fall', 'spring', 'spring', 'summer', 'fall', 'fall', 'summer', 'spring', 'fall', 'fall', 'summer', 'fall', 'fall', 'summer', 'fall', 'fall', 'summer', 'spring', 'fall', 'spring', 'spring', 'fall', 'fall', 'winter', 'spring', 'summer', 'fall', 'fall', 'fall', 'fall', 'winter', 'winter', 'fall', 'fall', 'fall', 'summer', 'spring', 'spring', 'winter', 'winter', 'summer', 'fall', 'spring', 'spring', 'fall', 'spring', 'winter', 'fall', 'fall', 'spring', 'spring', 'spring', 'fall', 'fall', 'winter', 'fall', 'winter', 'fall', 'fall', 'summer', 'spring', 'spring', 'summer', 'winter', 'spring', 'fall', 'fall', 'spring', 'summer', 'spring', 'summer', 'spring', 'fall', 'summer', 'winter', 'fall', 'winter', 'winter', 'winter', 'spring', 'summer', 'spring', 'fall', 'spring', 'summer', 'winter', 'summer', 'fall', 'fall', 'fall', 'spring', 'spring', 'spring', 'fall', 'fall', 'spring', 'fall', 'summer', 'fall', 'fall', 'spring', 'winter', 'fall', 'fall', 'spring', 'spring', 'fall', 'summer', 'winter', 'summer', 'fall', 'spring', 'fall', 'summer', 'summer', 'winter', 'spring', 'fall', 'summer', 'fall', 'fall', 'spring', 'spring', 'spring', 'fall', 'spring', 'fall', 'spring', 'winter', 'summer', 'fall', 'fall', 'spring', 'winter', 'fall', 'fall', 'summer', 'fall', 'fall', 'spring', 'fall', 'fall', 'summer', 'winter', 'fall', 'fall', 'fall', 'summer', 'spring', 'summer', 'summer', 'spring', 'fall', 'summer', 'spring', 'fall', 'summer', 'winter', 'fall', 'fall', 'fall', 'winter', 'fall', 'summer', 'winter', 'winter', 'fall', 'fall', 'fall', 'spring', 'summer', 'winter', 'winter', 'summer', 'fall', 'summer', 'spring', 'fall', 'fall', 'fall', 'fall', 'winter', 'spring', 'spring', 'fall', 'spring', 'summer', 'spring', 'spring', 'fall', 'fall', 'spring', 'fall', 'summer', 'spring', 'summer', 'fall', 'spring', 'fall', 'summer', 'fall', 'spring', 'fall', 'spring', 'spring', 'spring', 'spring', 'summer', 'fall', 'winter', 'summer', 'winter', 'fall', 'winter', 'fall', 'fall', 'fall', 'winter', 'fall', 'spring', 'fall', 'fall', 'fall', 'winter', 'spring', 'summer', 'fall', 'fall', 'fall', 'winter', 'spring', 'spring', 'winter', 'fall', 'fall', 'fall', 'summer', 'fall', 'spring', 'spring', 'fall', 'summer', 'winter', 'fall', 'fall', 'fall', 'winter', 'fall', 'spring', 'spring', 'spring', 'spring', 'winter', 'fall', 'fall', 'spring', 'summer', 'spring', 'summer', 'fall', 'fall', 'winter', 'spring', 'spring', 'fall', 'spring', 'winter', 'spring', 'summer', 'fall', 'fall', 'summer', 'fall', 'fall', 'spring', 'summer', 'fall', 'spring', 'fall', 'fall', 'fall', 'winter', 'fall', 'spring', 'fall', 'winter', 'spring', 'winter', 'winter', 'fall', 'fall', 'winter', 'summer', 'fall', 'summer', 'winter', 'summer', 'spring', 'winter', 'fall', 'fall', 'spring', 'fall', 'fall', 'fall', 'fall', 'fall', 'summer', 'spring', 'fall', 'summer', 'spring', 'fall', 'summer', 'fall', 'summer', 'winter', 'spring', 'fall', 'summer', 'winter', 'summer', 'fall', 'fall', 'winter', 'fall', 'fall', 'fall', 'summer', 'fall', 'summer', 'fall', 'fall', 'fall', 'spring', 'spring', 'fall', 'summer', 'spring', 'fall', 'fall', 'fall', 'fall', 'fall', 'summer', 'fall', 'fall', 'winter', 'spring', 'spring', 'fall', 'fall', 'winter', 'spring', 'fall', 'summer', 'fall', 'fall', 'winter', 'fall', 'winter', 'winter', 'fall', 'summer', 'fall', 'winter', 'fall', 'fall', 'fall', 'spring', 'winter', 'spring', 'summer', 'fall', 'spring', 'spring', 'fall', 'fall', 'fall', 'fall', 'summer', 'winter', 'winter', 'spring', 'fall', 'fall', 'winter', 'winter', 'fall', 'spring', 'spring', 'summer', 'spring', 'spring', 'summer', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'winter', 'spring', 'spring', 'spring', 'summer', 'fall', 'summer', 'spring', 'spring', 'fall', 'fall', 'fall', 'fall', 'fall', 'spring', 'winter', 'fall', 'winter', 'spring', 'spring', 'spring', 'summer', 'fall', 'winter', 'fall', 'fall', 'spring', 'spring', 'winter', 'fall', 'winter', 'winter', 'fall', 'fall', 'fall', 'spring', 'winter', 'fall', 'fall', 'fall', 'spring', 'fall', 'summer', 'spring', 'summer', 'spring', 'fall', 'summer', 'fall', 'fall', 'fall', 'spring', 'spring', 'fall', 'spring', 'fall', 'spring', 'winter', 'winter', 'summer', 'fall', 'summer', 'winter', 'spring', 'spring', 'spring', 'winter', 'fall', 'winter', 'winter', 'winter', 'fall', 'fall', 'summer', 'spring', 'spring', 'fall', 'summer', 'spring', 'spring', 'fall', 'fall', 'fall', 'summer', 'spring', 'summer', 'fall', 'spring', 'spring', 'winter', 'spring', 'fall', 'fall', 'fall', 'spring', 'fall', 'summer', 'summer', 'fall', 'fall', 'fall', 'fall', 'winter', 'fall', 'summer', 'fall', 'fall', 'fall', 'spring', 'summer', 'fall', 'winter', 'fall', 'fall', 'summer', 'fall', 'spring', 'fall', 'fall', 'fall', 'spring', 'fall', 'fall', 'fall', 'summer', 'spring', 'fall', 'spring', 'spring', 'fall', 'spring', 'spring', 'winter', 'summer', 'summer', 'fall', 'fall', 'summer', 'spring', 'spring', 'fall', 'summer', 'spring', 'winter', 'fall', 'fall', 'winter', 'summer', 'summer', 'summer', 'summer', 'summer', 'winter', 'summer', 'winter', 'winter', 'fall', 'summer', 'spring', 'summer', 'fall', 'spring', 'fall', 'winter', 'spring', 'spring', 'fall', 'spring', 'winter', 'summer', 'summer', 'spring', 'fall', 'winter', 'fall', 'fall', 'fall', 'spring', 'fall', 'fall', 'spring', 'spring', 'fall', 'winter', 'winter', 'summer', 'spring', 'fall', 'fall', 'summer', 'summer', 'summer', 'winter', 'summer', 'spring', 'winter', 'summer', 'fall', 'spring', 'fall', 'fall', 'summer', 'winter', 'winter', 'spring', 'fall', 'summer', 'fall', 'spring', 'spring', 'winter', 'fall', 'fall', 'fall', 'fall', 'winter', 'spring', 'fall', 'spring', 'winter', 'fall', 'winter', 'fall', 'fall', 'spring', 'fall', 'winter', 'fall', 'summer', 'fall', 'summer', 'winter', 'winter', 'spring', 'winter', 'fall', 'spring', 'summer', 'summer', 'summer', 'fall', 'spring', 'fall', 'spring', 'fall', 'spring', 'spring', 'fall', 'spring', 'winter', 'summer', 'fall', 'summer', 'fall', 'fall', 'spring', 'winter', 'fall', 'winter', 'summer', 'winter', 'spring', 'spring', 'spring', 'fall', 'winter', 'fall', 'summer', 'fall', 'winter', 'fall', 'spring', 'fall', 'fall', 'fall', 'fall', 'spring', 'spring', 'fall', 'spring', 'fall', 'fall', 'fall', 'fall', 'fall', 'spring', 'fall', 'fall', 'summer', 'fall', 'fall', 'fall', 'fall', 'summer', 'fall', 'fall', 'spring', 'summer', 'fall', 'spring', 'fall', 'spring', 'spring', 'spring', 'winter', 'winter', 'fall', 'spring', 'fall', 'winter', 'fall', 'spring', 'fall', 'fall', 'winter', 'fall', 'spring', 'fall', 'summer', 'winter', 'spring', 'fall', 'fall', 'summer', 'fall', 'winter', 'fall', 'summer', 'spring', 'fall', 'fall', 'spring', 'winter', 'fall', 'summer', 'summer', 'spring', 'winter', 'fall', 'fall', 'summer', 'fall', 'spring', 'spring', 'winter', 'spring', 'spring', 'fall', 'summer', 'spring', 'fall', 'winter', 'spring', 'fall', 'fall', 'spring', 'winter', 'fall', 'winter', 'winter', 'summer', 'fall', 'fall', 'fall', 'spring', 'fall', 'winter', 'summer', 'fall', 'fall', 'spring', 'fall', 'summer', 'fall', 'fall', 'fall', 'summer', 'spring', 'fall', 'spring', 'spring', 'fall', 'summer', 'fall', 'fall', 'winter', 'summer', 'fall', 'spring', 'fall', 'summer', 'fall', 'winter', 'fall', 'fall', 'spring', 'summer', 'fall', 'spring', 'fall', 'winter', 'spring', 'spring', 'summer', 'fall', 'summer', 'spring', 'winter', 'fall', 'spring', 'fall', 'fall', 'winter', 'winter', 'winter', 'summer', 'fall', 'spring', 'fall', 'fall', 'winter', 'summer', 'winter', 'summer', 'spring', 'fall', 'fall', 'spring', 'summer', 'spring', 'summer', 'fall', 'fall', 'fall', 'summer', 'fall', 'fall', 'fall', 'winter', 'summer', 'fall', 'summer', 'spring', 'spring', 'fall', 'summer', 'spring', 'summer', 'spring', 'fall', 'fall', 'summer', 'winter', 'spring', 'winter', 'fall', 'fall', 'fall', 'summer', 'summer', 'winter', 'winter', 'fall', 'winter', 'fall', 'summer', 'spring', 'winter', 'fall', 'fall', 'spring', 'fall', 'fall', 'fall', 'fall', 'fall', 'spring', 'fall', 'summer', 'spring', 'spring', 'winter', 'spring', 'summer', 'fall', 'winter', 'spring', 'fall', 'summer', 'winter', 'spring', 'spring', 'spring', 'spring', 'fall', 'fall', 'spring', 'summer', 'fall', 'spring', 'fall', 'spring', 'fall', 'fall', 'summer', 'spring', 'winter', 'winter', 'spring', 'spring', 'fall', 'spring', 'winter', 'summer', 'fall', 'fall', 'fall', 'winter', 'spring', 'spring', 'fall', 'spring', 'fall', 'spring', 'fall', 'spring', 'fall', 'fall', 'fall', 'fall', 'fall', 'summer', 'summer', 'spring', 'winter', 'fall', 'fall', 'fall', 'winter', 'summer', 'fall', 'fall', 'winter', 'spring', 'spring', 'fall', 'spring', 'fall', 'spring', 'fall', 'spring', 'spring', 'spring', 'summer', 'fall', 'fall', 'spring', 'spring', 'summer', 'fall', 'summer', 'winter', 'fall', 'fall', 'summer', 'fall', 'fall', 'fall', 'fall', 'summer', 'fall', 'winter', 'winter', 'fall', 'spring', 'spring', 'fall', 'winter', 'winter', 'fall', 'spring', 'summer', 'spring', 'summer', 'fall', 'fall', 'summer', 'fall', 'spring', 'spring', 'spring', 'fall', 'spring', 'summer', 'summer', 'fall', 'fall', 'spring', 'winter', 'fall', 'spring', 'winter', 'winter', 'fall', 'summer', 'summer', 'spring', 'spring', 'winter', 'spring', 'summer', 'summer', 'fall', 'spring', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'summer', 'fall', 'fall', 'spring', 'winter', 'spring', 'spring', 'fall', 'spring', 'spring', 'spring', 'fall', 'fall', 'fall', 'fall', 'summer', 'fall', 'spring', 'summer', 'summer', 'spring', 'fall', 'fall', 'winter', 'fall', 'fall', 'fall', 'fall', 'fall', 'winter', 'summer', 'winter', 'fall', 'spring', 'spring', 'summer', 'winter', 'fall', 'summer', 'fall', 'winter', 'spring', 'spring']\n"
     ]
    }
   ],
   "source": [
    "# 예측 결과를 원래 태그로 변환\n",
    "predictions = model.predict(\n",
    "   {'input_ids':x_test['input_ids'],'attention_mask':x_test['attention_mask']})\n",
    "predicted_tags = np.argmax(predictions, axis=1)\n",
    "predicted_tags = [inverse_tag_mapping[tag] for tag in predicted_tags]\n",
    "\n",
    "print(\"Predicted Tags:\", predicted_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79b006ad-f902-41cb-8429-f21256acb70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.45      0.44       696\n",
      "           1       0.68      0.49      0.57       707\n",
      "           2       0.38      0.67      0.49       680\n",
      "           3       0.48      0.27      0.34       772\n",
      "\n",
      "    accuracy                           0.46      2855\n",
      "   macro avg       0.49      0.47      0.46      2855\n",
      "weighted avg       0.49      0.46      0.46      2855\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 예측 결과와 실제 레이블을 가지고 classification report 생성\n",
    "y_true = test.태그_encoded\n",
    "y_pred =np.argmax(predictions, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "972721ea-fb59-4734-9df3-2ee3359e9ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 겨울 아침 \n"
     ]
    }
   ],
   "source": [
    "a=input()\n",
    "b=tokenizer(\n",
    "    text=a,\n",
    "    add_special_tokens=True,\n",
    "    max_length=200,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "155855d6-9273-4cd8-a123-59f5e8f4b12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n",
      "Predicted Tags: ['fall']\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict({'input_ids': b['input_ids'], 'attention_mask': b['attention_mask']})\n",
    "predicted_tags = np.argmax(predictions, axis=1)\n",
    "predicted_tags = [inverse_tag_mapping[tag] for tag in predicted_tags]\n",
    "print(\"Predicted Tags:\", predicted_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e620b460-af1b-401c-919c-6326ddb35d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./model/time/season2_weights')\n",
    "model.save('./model/time/season2.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
